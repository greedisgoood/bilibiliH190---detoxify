import os
import re
import json
import time
import torch
import numpy as np
from transformers import BertTokenizer, BertModel
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import logging
from datetime import datetime

class HuaweiFanaticDetector:
    def __init__(self):
        """åˆå§‹åŒ–åä¸ºæç«¯ç²‰ä¸æ£€æµ‹å™¨"""
        self._init_logging()
        self._init_feature_weights_and_patterns()
        self._init_special_terms_and_mappings()
        self._init_sentiment_analysis_resources() # æ›¿æ¢ _init_ml_model
        self._init_detoxify_model()
        self.expand_variant_mapping() # æ‰©å±•å˜ä½“è¯å’Œè°éŸ³è¯å¤„ç†

        self.logger.info("åä¸ºæç«¯ç²‰ä¸æ£€æµ‹å™¨å·²åˆå§‹åŒ– (æ•´åˆè§„åˆ™å’ŒDetoxify)")

    def expand_variant_mapping(self):
        """æ‰©å±•å˜ä½“è¯æ˜ å°„"""
        # ä½¿ç”¨æ›´å…¨é¢çš„å˜ä½“è¯åº“
        additional_mappings = {
            # å°ç±³ç›¸å…³
            "å°ç±³": ["å°è¿·", "å°å’ª", "å°èœœ", "æ ¡ç±³", "å°è°œ", "xm", "å°ç±³å­", "å°ç±³ç±³"],
            "åä¸º": ["èŠ±ä¸º", "åå¨", "åå¾®", "èŠ±å¨", "æ»‘å¨", "hw", "åå", "åä»”"],
            "é¸¿è’™": ["çº¢è’™", "çƒ˜è’™", "æ´ªè’™", "é¸¿æ¢¦", "çº¢æ¢¦", "hmxt", "é¸¿é—¨"],
            "é›·å†›": ["ç´¯å†›", "ç£Šå†›", "è•¾å†›", "ç±»å†›", "é›·ä¿Š", "é›·ä¸ç¾¤", "é›·æ€»", "é›·è€æ¿"],
            "è‹¹æœ": ["å¹³æœ", "å“æœ", "è‹¹è£¹", "å¹³è£¹", "pg", "æœæœ", "æœå­"],
            "å®‰å“": ["å®‰æ¡Œ", "å®‰ç¼", "å²¸å“", "æŒ‰å“", "az", "aæ¡Œ", "aå“"]
        }

        # æ›´æ–°æ˜ å°„è¡¨
        for standard, variants in additional_mappings.items():
            for variant in variants:
                self.variant_mapping[variant] = standard

        # æ·»åŠ æ›´å¤šå°ç±³è´Ÿé¢è¯æ±‡
        additional_negative_terms = [
            "ç±³çŒ´", "ç±³è›€", "æ²™é›•ç±³", "ç²—ç²®", "å·å›½", "å››æ£’", "å† ", "å·ç±³",
            "é«˜è´µç±³", "ç§»åŠ¨æ£±æ", "æ™ºå•†ç¨", "ç‚¸å¼¹", "åºŸé“", "å¤–è¡Œ", "éª—å­",
            "å™ªå¤´", "PPT", "ä¸ä¸­ç”¨", "å±é™©", "äº‹æ•…", "è½¦ç¥¸", "æ­»äº¡", "è‡´æ­»",
            "è‡ªæ€", "é€å‘½", "æ‰¾æ­»", "ç­‰æ­»", "è´´ç‰Œ", "ç»„è£…å‚", "ä¹°åŠ", "é›·ä¸ç¾¤",
            "è¹­", "é›·å¸ƒæ–¯", "é›·åœ£", "é›·ä¸ç¾¤", "ç±³ç²‰", "ç±³åˆ†", "ç±³èŠ¬", "ç±³ä»½",
            "è¿·ç²‰", "å’ªç²‰", "è¿·åˆ†"
        ]

        for term in additional_negative_terms:
            if term not in self.xiaomi_negative_terms:
                self.xiaomi_negative_terms.append(term)

        # æ·»åŠ æ›´å¤šåä¸ºç‰¹æ®Šæœ¯è¯­
        additional_huawei_terms = [
            "èŠ±ä¸º", "åå¨", "åå¾®", "èŠ±å¨", "æ»‘å¨", "hw", "åå", "åä»”",
            "çº¢è’™", "çƒ˜è’™", "æ´ªè’™", "é¸¿æ¢¦", "çº¢æ¢¦", "hmxt", "é¸¿é—¨"
        ]

        for term in additional_huawei_terms:
            if term not in self.huawei_special_terms:
                self.huawei_special_terms.append(term)

        # æ·»åŠ æ›´å¤šå°ç±³ç‰¹æ®Šæœ¯è¯­
        additional_xiaomi_terms = [
            "å°è¿·", "å°å’ª", "å°èœœ", "æ ¡ç±³", "å°è°œ", "xm", "å°ç±³å­", "å°ç±³ç±³",
            "ç´¯å†›", "ç£Šå†›", "è•¾å†›", "ç±»å†›", "é›·ä¿Š", "é›·å¸ƒæ–¯", "é›·æ€»", "é›·è€æ¿",
            "é›·ä¸ç¾¤", "é›·åœ£"
        ]

        for term in additional_xiaomi_terms:
            if term not in self.xiaomi_special_terms:
                self.xiaomi_special_terms.append(term)

        self.logger.info("å˜ä½“è¯æ˜ å°„å’Œç‰¹æ®Šæœ¯è¯­å·²æ‰©å±•")

    def _init_logging(self):
        """åˆå§‹åŒ–æ—¥å¿—è®°å½•åŠŸèƒ½"""
        log_dir = "logs"
        if not os.path.exists(log_dir):
            os.makedirs(log_dir)
        current_time = datetime.now().strftime("%Y%m%d_%H%M%S")
        log_file = os.path.join(log_dir, f"fanatic_detector_{current_time}.log")

        self.logger = logging.getLogger("HuaweiFanaticDetector")
        if not self.logger.handlers: # é˜²æ­¢é‡å¤æ·»åŠ å¤„ç†å™¨
            self.logger.setLevel(logging.INFO)
            file_handler = logging.FileHandler(log_file, encoding="utf-8")
            file_handler.setLevel(logging.INFO)
            console_handler = logging.StreamHandler()
            console_handler.setLevel(logging.WARNING)
            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
            file_handler.setFormatter(formatter)
            console_handler.setFormatter(formatter)
            self.logger.addHandler(file_handler)
            self.logger.addHandler(console_handler)
            self.logger.info(f"æ—¥å¿—æ–‡ä»¶: {log_file}")

        self.detection_count = 0
        self.extreme_count = 0

    def _init_feature_weights_and_patterns(self):
        """åˆå§‹åŒ–ç‰¹å¾æƒé‡å’Œæ‰€æœ‰æ£€æµ‹æ¨¡å¼"""
        self.feature_weights = {
            # è§„åˆ™æ£€æµ‹ç±»åˆ«æƒé‡
            "blind_worship": 1.8,
            "conspiracy_theory": 2.5, # æé«˜
            "competitor_attack": 2.5, # æé«˜
            "nationalism": 2.0,
            "tech_exaggeration": 1.6,
            "extreme_speech": 2.8, # æé«˜
            "xiaomi_accident_attack": 3.5, # å¤§å¹…æé«˜
            "sarcasm_irony": 2.2, # æ–°å¢ç±»åˆ«
            "schadenfreude_double_standard": 2.6, # æ–°å¢ç±»åˆ«
            "information_manipulation_accusation": 2.4, # æ–°å¢ç±»åˆ«
            "user_group_attack": 2.3, # æ–°å¢ç±»åˆ«
            "generalization_attack": 2.1 # æ–°å¢ç±»åˆ«
        }

        # åˆ¤å®šé˜ˆå€¼ (è°ƒæ•´ä»¥å¹³è¡¡å‡†ç¡®ç‡)
        self.malicious_threshold_rule = 2.4 # è§„åˆ™æ£€æµ‹é˜ˆå€¼ (æé«˜)
        self.confidence_threshold_final = 0.60 # æœ€ç»ˆç½®ä¿¡åº¦é˜ˆå€¼ (æé«˜)
        self.high_risk_score_threshold = 3.0 # ç‰¹å®šé«˜é£é™©æ¨¡å¼è§¦å‘åˆ†æ•°é˜ˆå€¼ (ä¿æŒ)
        self.high_toxicity_score_threshold = 1.5 # è‡ªå®šä¹‰é«˜æ¯’æ€§åˆ†æ•°ç›´æ¥è§¦å‘é˜ˆå€¼ (å¤§å¹…æé«˜)

        # ç¼–è¯‘æ ‡å¿—
        flags = re.IGNORECASE | re.UNICODE

        # æ•´åˆæ‰€æœ‰æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
        self.all_patterns = {
            # --- è§„åˆ™æ£€æµ‹ä¸»è¦ç±»åˆ« ---
            "blind_worship": [
                re.compile(p, flags) for p in [
                    r"åä¸º.{0,5}(æœ€å¼º|æ— æ•Œ|ç¬¬ä¸€|é¢†å…ˆå…¨çƒ|éœ‡æƒŠä¸–ç•Œ|é¢†å…ˆ\d+å¹´)",
                    r"(ä»»æ­£é|ä½™æ‰¿ä¸œ|åä¸º|é¸¿è’™).{0,10}(ä¼Ÿå¤§|å¤©æ‰|ç¥|ç¡¬æ ¸|æ”¹å˜ä¸–ç•Œ)",
                    r"åä¸º.{0,5}(å·²ç»|å…¨é¢|å½»åº•)(é¢†å…ˆ|è¶…è¶Š)(è‹¹æœ|ä¸‰æ˜Ÿ|å°ç±³|è°·æ­Œ|å…¨çƒ|å…¨ä¸–ç•Œ)",
                    r"(ç›¸ä¿¡|æ”¯æŒ)åä¸º(å°±æ˜¯|ç­‰äº)(ç›¸ä¿¡|æ”¯æŒ)ä¸­å›½",
                    r"ä¸­å›½äººå°±è¯¥ç”¨åä¸º", r"åä¸ºæ˜¯ä¸­å›½çš„éª„å‚²",
                    r"é¸¿è’™.{0,5}(è¶…è¶Š|ç¢¾å‹|åŠæ‰“)(å®‰å“|iOS|è‹¹æœ|è°·æ­Œ)",
                    r"åä¸º.{0,5}(ä¸æ„§æ˜¯|å°±æ˜¯|æœç„¶æ˜¯)å›½äº§(ä¹‹å…‰|éª„å‚²|ç¬¬ä¸€|æ ‡æ†)",
                    r"åä¸º.{0,5}(æŠ€æœ¯|èŠ¯ç‰‡|ç³»ç»Ÿ).{0,10}(å‚²è§†|é¢†å…ˆ)(å…¨çƒ|ä¸–ç•Œ)",
                    r"åä¸º.{0,5}(å”¯ä¸€|ç‹¬ä¸€æ— äºŒ|æ— å¯æ›¿ä»£)",
                    r"æ²¡æœ‰(å¯¹æ¯”|å¯¹æ‰‹)å°±æ²¡æœ‰(ä¼¤å®³|å‹åŠ›)"
                ]
            ],
            "conspiracy_theory": [
                re.compile(p, flags) for p in [
                    r"ç¾å›½.{0,5}(æ‰“å‹|å°é”|åˆ¶è£|å›´å‰¿)åä¸º",
                    r"è¥¿æ–¹.{0,5}(æ‰“å‹|å°é”|åˆ¶è£|å›´å‰¿)(åä¸º|ä¸­å›½)",
                    r"(æŠ¹é»‘|é»‘)åä¸º", r"åä¸º.{0,5}(é­åˆ°|è¢«)(æ‰“å‹|å°é”|åˆ¶è£)",
                    r"å¤–å›½(åŠ¿åŠ›|åª’ä½“|å…¬å¸).{0,10}(æ‰“å‹|æŠ¹é»‘|æ±¡è”‘)(åä¸º|ä¸­å›½)",
                    r"åä¸º.{0,10}è¢«.{0,5}(é’ˆå¯¹|æ‰“å‡»|å°æ€)",
                    r"ä¸å…è®¸.{0,5}åä¸º(å´›èµ·|å¼ºå¤§)",
                    r"åä¸º.{0,5}(å¨èƒ).{0,5}(ç¾å›½|è¥¿æ–¹)(åˆ©ç›Š|å®‰å…¨)",
                    # æ–°å¢
                    r"æ¶ˆæ¯æ‰å‡ºæ¥.*?ä¸‰å¤©", r"å®é™…æƒ…å†µè§†é¢‘ä¸€ç›´éƒ½æ²¡çœ‹åˆ°",
                    r"è¡Œè½¦è®°å½•ä»ªéƒ½èƒ½æ˜¾ç¤ºæ¸…æ¥š", r"æ²‰é»˜.*?ä¸‰å¤©åæ‰å‘å£°",
                    r"å¥—ç°.*?äº¿", r"åˆ«æ§ä»€ä¹ˆå…¬å…³", r"å…³æ³¨çš„æ˜¯ç»“æœå’Œè¿‡ç¨‹",
                    r"çŠ¹å¤ªèµ„æœ¬" # æ–°å¢
                ]
            ],
            "competitor_attack": [
                re.compile(p, flags) for p in [
                    r"(è‹¹æœ|ä¸‰æ˜Ÿ|å°ç±³|OPPO|vivo|è£è€€).{0,5}(åƒåœ¾|è¾£é¸¡|æ¸£|å±)",
                    r"(é«˜é€š|è”å‘ç§‘|éªé¾™|å¤©ç‘).{0,5}(åƒåœ¾|è¾£é¸¡|æ¸£|å±)",
                    r"(å®‰å“|iOS).{0,5}(åƒåœ¾|è¾£é¸¡|æ¸£|å±)", # ç§»é™¤é¸¿è’™è‡ªæ”»å‡»
                    r"(ç±³ç²‰|æœç²‰|ä¸‰æ£’).{0,5}(è„‘æ®‹|æ™ºéšœ|ç²¾ç¥ç—…|è ¢)",
                    r"(é›·å†›|åº“å…‹|å°ç±³|è‹¹æœ).{0,5}(å¹ç‰›|é€ å‡|è¥é”€|æŠ„è¢­|å±±å¯¨)",
                    r"(ç±³|æœ|ç»´|ä¸‰)(çŒ´|è›†|ç‹—)",
                    r"(å°ç±³|è‹¹æœ|OPPO|vivo)(æ¨¡ä»¿|æŠ„è¢­|å€Ÿé‰´|å±±å¯¨)åä¸º",
                    r"(è‹¹æœ|è°·æ­Œ|é«˜é€š)(ç»™åä¸º|åä¸ºé¢å‰)(è·ªäº†|ä¸‹è·ª|è®¤æ€‚|æœè½¯)",
                    r"åä¸º(ç§’æ€|åŠæ‰“|ç¢¾å‹)(å°ç±³|è‹¹æœ|ä¸‰æ˜Ÿ|è°·æ­Œ)",
                    r"(éº’éºŸ|é¸¿è’™|åä¸º)(ç§’æ€|åŠæ‰“|ç¢¾å‹)(éªé¾™|å®‰å“|iOS)",
                    r"(ç¬‘æ­»|å¥½ç¬‘)(å›½äº§|å°ç±³|è‹¹æœ)è¿˜æƒ³(èµ¶è¶…|æ¯”è‚©)åä¸º",
                    r"(å°ç±³|è‹¹æœ|ä¸‰æ˜Ÿ)(æ°¸è¿œ)(æ´»åœ¨|æ¨¡ä»¿|è·Ÿåœ¨)(åä¸º|é¸¿è’™)(é˜´å½±ä¸‹|èº«å)",
                    r"å°ç±³å°±æ˜¯ä¸€è´´ç‰Œå…¬å¸", # æ–°å¢
                    r"å°ç±³.*?ç»„è£…å‚", # æ–°å¢
                    r"é›·ä¸ç¾¤", # æ–°å¢
                    r"å°ç±³.*?ä¹°åŠ", # æ–°å¢
                    r"å°ç±³.*?é è¥é”€", # æ–°å¢
                    r"å°ç±³.*?ä»€ä¹ˆéƒ½æ’ä¸€è„š", # æ–°å¢
                    r"å°ç±³.*?åƒæ›¾ç»çš„è…¾è®¯.*?æ”¶å‰²", # æ–°å¢
                    r"å°ç±³.*?å“ç‰Œéœ¸æƒ" # æ–°å¢
                ]
            ],
             "user_group_attack": [ # æ‹†åˆ†ç”¨æˆ·ç¾¤ä½“æ”»å‡»
                re.compile(p, flags) for p in [
                    r"å°ç±³.*?ç”¨æˆ·ç¾¤ä½“.*?æ˜¯ä»€ä¹ˆäºº", r"ä¸ªæ€§å¹´è½»äºº.*?å–œæ¬¢é£™è½¦",
                    r"ä¹°å°ç±³.*?è™šè£å¿ƒ", r"ç±³ç²‰çœŸçš„ä¿¡ä»°.*?é¡¶å³°",
                    r"ç±³ç²‰.*?(è ¢|å‚»|ç¬¨|å¼±æ™º|è„‘æ®‹)",
                    r"(çŒ´|è›†|ç²‰ä¸|æ°´å†›).*?(æ´—åœ°|æ´—ç™½|æŠ¤ä¸»|æŠ¤èˆª|è·ªèˆ”)",
                    r"(è›†|çŒ´)(å­|ä»¬).*?(åˆ|å†|ç»§ç»­).*?(æ´—åœ°|æ´—ç™½|è¾©è§£)"
                ]
            ],
            "generalization_attack": [ # æ‹†åˆ†æ³›åŒ–æ”»å‡»
                re.compile(p, flags) for p in [
                    r"å°ç±³.*?æ€§ä»·æ¯”.*?è´¨é‡å·®.*?æ²¡å”®å",
                    r"ä½ å»æœä¸€ä¸‹.*?å‡ å®¶", # æ–°å¢
                    r"å°ç±³æ±½è½¦å‡ºé—®é¢˜çš„è²Œä¼¼éƒ½æ˜¯æ“ä½œäººçš„é—®é¢˜", # æ–°å¢ (åå‘è®½åˆº)
                    r"åˆ°ç°åœ¨è¿˜æœ‰ç»™å°ç±³.*?æ ‡ç­¾" # æ–°å¢
                ]
            ],
            "nationalism": [
                 re.compile(p, flags) for p in [
                    r"åä¸º.{0,5}(æœ€å¼º|æ— æ•Œ|ç¬¬ä¸€|é¢†å…ˆå…¨çƒ|éœ‡æƒŠä¸–ç•Œ|é¢†å…ˆ\d+å¹´)", # éƒ¨åˆ†å´‡æ‹œå½’å…¥æ­¤ç±»
                    r"åä¸º.{0,5}(å·²ç»|å…¨é¢|å½»åº•)(é¢†å…ˆ|è¶…è¶Š)(è‹¹æœ|ä¸‰æ˜Ÿ|å°ç±³|è°·æ­Œ|å…¨çƒ|å…¨ä¸–ç•Œ)", # éƒ¨åˆ†å´‡æ‹œå½’å…¥æ­¤ç±»
                    r"(ç›¸ä¿¡|æ”¯æŒ)åä¸º(å°±æ˜¯|ç­‰äº)(ç›¸ä¿¡|æ”¯æŒ)ä¸­å›½",
                    r"ä¸­å›½äººå°±è¯¥ç”¨åä¸º", r"åä¸ºæ˜¯ä¸­å›½çš„éª„å‚²",
                    r"åä¸º.{0,5}(ä¸æ„§æ˜¯|å°±æ˜¯|æœç„¶æ˜¯)å›½äº§(ä¹‹å…‰|éª„å‚²|ç¬¬ä¸€|æ ‡æ†)",
                    r"åä¸º.*?æ°‘æ—.*?(éª„å‚²|å“ç‰Œ|ä¼ä¸š)",
                    r"åä¸º.*?å›½å®¶.*?(éª„å‚²|å“ç‰Œ|ä¼ä¸š)",
                    r"åä¸º.*?å›½äº§.*?(éª„å‚²|å“ç‰Œ|ä¼ä¸š)",
                    r"åä¸º.*?ä¸­å›½.*?(éª„å‚²|å“ç‰Œ|ä¼ä¸š)",
                    r"æ”¯æŒåä¸º.*?çˆ±å›½", r"ç”¨åä¸º.*?çˆ±å›½",
                    r"ä¸ç”¨åä¸º.*?å°±æ˜¯.*?(å–å›½|æ±‰å¥¸)" # æç«¯å¯¹ç«‹
                ]
            ],
            "tech_exaggeration": [
                re.compile(p, flags) for p in [
                    r"åä¸º.{0,5}(æŠ€æœ¯|èŠ¯ç‰‡|ç³»ç»Ÿ).{0,10}(å‚²è§†|é¢†å…ˆ)(å…¨çƒ|ä¸–ç•Œ)",
                    r"é¸¿è’™.{0,5}(è¶…è¶Š|ç¢¾å‹|åŠæ‰“)(å®‰å“|iOS|è‹¹æœ|è°·æ­Œ)",
                    r"åä¸º.{0,5}(å”¯ä¸€|ç‹¬ä¸€æ— äºŒ|æ— å¯æ›¿ä»£)",
                    r"(ç¬¬ä¸€|é¥é¥é¢†å…ˆ).*?(ota|è·‘åˆ†|æ¨¡ç³Šæ¦‚å¿µ|ç«™ç¨³)" # æ–°å¢è®½åˆºæ€§é¢†å…ˆ
                ]
            ],
            "extreme_speech": [
                re.compile(p, flags) for p in [
                    r"è¯…å’’.*?ä¸€å®¶.*?æ‚²æƒ¨", # åŒ…å«è¯…å’’
                    r"é™¤æ‰.*?è¿™äº›", # æš´åŠ›å€¾å‘
                    r"æ³•åŠ¡éƒ¨.*?è°ƒæŸ¥" # å¨èƒå€¾å‘
                ]
            ],
            # --- ä¸»è¦é’ˆå¯¹å°ç±³æ±½è½¦çš„æ”»å‡» ---
            "xiaomi_accident_attack": [
                # ä½¿ç”¨ä¼˜åŒ–åçš„æ­£åˆ™è¡¨è¾¾å¼ï¼Œæ›´ç²¾ç¡®åŒ¹é…æ¶æ„è¨€è®ºè€Œéæ­£å¸¸è®¨è®º
                re.compile(p, flags) for p in [
                    # è´¨é‡/èƒ½åŠ›/åŠ¨æœºæ‰¹è¯„ - æ›´ç²¾ç¡®åŒ¹é…æ¶æ„è¨€è®º
                    r"å°ç±³.*?(è½¦|æ±½è½¦|SU7|su7).*?(åƒåœ¾|è¾£é¸¡|ä¸ä¸­ç”¨|åºŸé“|åºŸç‰©)(?!.*ä½†æ˜¯è¿˜æ˜¯å¾ˆæœŸå¾…)(?!.*å¸Œæœ›æ”¹è¿›)",
                    r"(é›·å†›|å°ç±³).*?(é€ è½¦|åšè½¦).*?(å¤±è´¥|ç¬‘è¯|å¤–è¡Œ|ä¸æˆäº‹)(?!.*ä½†æ˜¯åœ¨åŠªåŠ›)(?!.*å¸Œæœ›æ”¹è¿›)",
                    r"æ‰‹æœºå‚.*?(é€ è½¦|åšè½¦).*?(ä¸æ‡‚|ä¸ä¼š|å¤–è¡Œ|è‡ªä¸é‡åŠ›)(?!.*ä½†æ˜¯åœ¨å­¦ä¹ )",

                    # æ™ºé©¾/å®‰å…¨æ€§è´¨ç–‘ - æ›´ç²¾ç¡®åŒ¹é…æ¶æ„è¨€è®ºè€Œéæ­£å¸¸è®¨è®º
                    r"å°ç±³.*?(è½¦|æ±½è½¦|SU7|su7).*?(æ™ºé©¾|æ™ºèƒ½é©¾é©¶).*?(åƒåœ¾|å¤±è´¥|ç¬‘è¯|ä¸€å¨)(?!.*ä½†åœ¨æ”¹è¿›)(?!.*å¸Œæœ›æå‡)",
                    r"(é›·å†›|å°ç±³).*?æŠŠ.*?(å‘½|ç”Ÿå‘½|å®‰å…¨).*?å½“.*?æ€§ä»·æ¯”(?!.*è¿™æ˜¯è°£è¨€)",

                    # äº‹æ•…ç›¸å…³ç›´æ¥æ”»å‡»/è¯…å’’ - åŒºåˆ†äº‹å®é™ˆè¿°å’Œæ¶æ„è¯„è®º
                    r"(è½¦ç¥¸|äº‹æ•…|å‡ºäº‹|æ­»äº¡).*?(å°ç±³|é›·å†›).*?(å›æ—‹é•–|æŠ¥åº”|ç¦æŠ¥|æ¶æŠ¥|è¯¥æ­»|æ´»è¯¥|æŠ¥å¤|è‡ªé£Ÿæ¶æœ|æ¶è‡­|æ¶å¿ƒ)(?!.*å¸Œæœ›ä¸è¦å†å‘ç”Ÿ)",
                    r"(å°ç±³|é›·å†›).*?(è½¦|æ±½è½¦|SU7|su7).*?(æ€äºº|å¤ºå‘½|è‡´æ­»|ç´¢å‘½|å‡ºäººå‘½)(?!.*è¿™æ˜¯è°£è¨€)(?!.*å¸Œæœ›æ”¹è¿›å®‰å…¨æ€§)",
                    r"è¯…å’’.*?(å°ç±³ç²‰ä¸|ä¹°å°ç±³è½¦|ç±³ç²‰|ç±³è›€|ç±³çŒ´).*?æ‚²æƒ¨",

                    # ç§»åŠ¨æ£±æ/æµ‹è¯•ç»“æœ - æ›´ç²¾ç¡®åŒ¹é…æ¶æ„è¨€è®º
                    r"ç§»åŠ¨(æ£±æ|ç‚¸å¼¹|å¢“åœ°).*?(å°ç±³|é›·å†›).*?(è½¦|æ±½è½¦|SU7|su7)(?!.*è¿™æ˜¯è°£è¨€)",
                    r"æµ‹è¯•ç»“æœ.*?ä¹˜å®¢å…¨éƒ¨ç¢³åŒ–(?!.*è¿™æ˜¯è°£è¨€)",

                    # å…¬å…³/è´£ä»»/ä¿¡æ¯æŒç›–è´¨ç–‘ - åŒºåˆ†äº‹å®é™ˆè¿°å’Œæ¶æ„è¯„è®º
                    r"(å°ç±³|é›·å†›).*?(å…¬å…³|è°è¨€|æ¬ºéª—|å¿½æ‚ |éšç’).*?(è½¦|æ±½è½¦|äº‹æ•…|è½¦ç¥¸)(?!.*è¿™æ˜¯è°£è¨€)(?!.*å¸Œæœ›å…¬å¼€é€æ˜)",
                    r"(å‡ºäº‹|è½¦ç¥¸|äº‹æ•…).*?ç†ä¸­å®¢.*?(æ´—åœ°|æ´—ç™½|è¾©è§£)(?!.*å¸Œæœ›å…¬å¼€é€æ˜)",
                    r"(å°ç±³|é›·å†›).*?(è½¦|æ±½è½¦|SU7|su7).*?(ä¸ä¼š|æ²¡æœ‰).*?(è®¤é”™|é“æ­‰|æ‰¿æ‹…è´£ä»»)(?!.*è¿™æ˜¯è°£è¨€)(?!.*å¸Œæœ›æ‰¿æ‹…è´£ä»»)",

                    # åŸæœ‰æ¨¡å¼

                    # è´¨é‡/èƒ½åŠ›/åŠ¨æœºæ‰¹è¯„
                    r"å°ç±³.*?(è½¦|æ±½è½¦|SU7|su7).*?(åƒåœ¾|ä¸è¡Œ|è¾£é¸¡|ä¸ä¸­ç”¨|åºŸé“|åºŸç‰©)",
                    r"(é›·å†›|å°ç±³).*?(é€ è½¦|åšè½¦).*?(ä¸è¡Œ|å¤±è´¥|ç¬‘è¯|ä¸æ‡‚|å¤–è¡Œ|ä¸æˆäº‹)",
                    r"æ‰‹æœºå‚.*?(é€ è½¦|åšè½¦)", r"(å°ç±³|é›·å†›).*?(å¹ç‰›|ç¥è¯ç ´ç­|éª—å­).*?è½¦",
                    r"(å°ç±³|é›·å†›).*?è½¦.*?(è¥é”€|å™±å¤´|PPT|æ¦‚å¿µ|æ™ºå•†ç¨)",
                    r"è°.*?æ•¢.*?å.*?å°ç±³.*?è½¦", r"å°ç±³.*?è½¦.*?å½“.*?å°ç™½é¼ ",
                    r"(è½¦|æ±½è½¦|SU7|su7).*?(éª—|ä¸å€¼å¾—|å‰²éŸ­èœ|æ”¶æ™ºå•†ç¨)",
                    r"(å°ç±³|é›·å†›).*?(ä¸æ‡‚|ä¸ä¼š|å¤–è¡Œ|å†…è¡Œ|åŠæ¡¶æ°´).*?(é€ è½¦|åšè½¦|æ±½è½¦)",
                    r"ä¸(æ•¢|ä¼š).*?(ä¹°|é€‰æ‹©|ä¿¡ä»»).*?å°ç±³.*?(è½¦|æ±½è½¦)",
                    r"(å°ç±³|é›·å†›).*?(å¹ç‰›|ç‰›çš®|ç”»é¥¼|å¿½æ‚ ).*?(ç ´ç­|æ‰“è„¸|è½ç©º|ç°å®)",
                    # æ™ºé©¾/å®‰å…¨æ€§è´¨ç–‘
                    r"å°ç±³.*?(è½¦|æ±½è½¦|SU7|su7).*?(æ™ºé©¾|æ™ºèƒ½é©¾é©¶).*?(ä¸æ•¢|ä¸è¡Œ|åƒåœ¾|å¤±è´¥|ç¬‘è¯|ä¿¡ä¸è¿‡|ä¸€å¨)", # å¢å¼º
                    r"(é›·å†›|å°ç±³).*?æŠŠ.*?(å‘½|ç”Ÿå‘½|å®‰å…¨).*?å½“.*?æ€§ä»·æ¯”",
                    r"(é›·å†›|å°ç±³).*?æŠ€æœ¯.*?èœ.*?è‡ªä¿¡",
                    r"(é›·å†›|å°ç±³).*?(é€ |ç ”å‘).*?æ™ºé©¾.*?(ä¸¢äºº|å±é™©|ä¸è´Ÿè´£)",
                    r"ä½é….*?å¼€.*?æ™ºé©¾.*?(å°ç±³)",
                    r"å’‹éƒ½ä¸è®¨è®º.*?è¿ä¸ªå±é™©åˆ¹è½¦éƒ½ä¸åš", # æ–°å¢
                    r"è‡ªå®¶æ™ºé©¾.*?ä¸€å¨", # æ–°å¢
                    r"é”€å”®.*?ä¸æ•¢ææ™ºé©¾", # æ–°å¢
                    # äº‹æ•…ç›¸å…³ç›´æ¥æ”»å‡»/è¯…å’’
                    r"(è½¦ç¥¸|äº‹æ•…|å‡ºäº‹|æ­»äº¡|æ­»äº†äºº).*?(å°ç±³|é›·å†›).*?(å›æ—‹é•–|æŠ¥åº”|ç¦æŠ¥|æ¶æŠ¥|è¯¥æ­»|æ´»è¯¥|æŠ¥å¤|ç»ˆä¼šåˆ°æ¥|è‡ªé£Ÿæ¶æœ|æ¶è‡­|æ¶å¿ƒ)",
                    r"(å°ç±³|é›·å†›).*?(è½¦|æ±½è½¦|SU7|su7).*?(æ€äºº|å¤ºå‘½|è‡´æ­»|ç´¢å‘½|å‡ºäººå‘½)",
                    r"è¯…å’’.*?(å°ç±³ç²‰ä¸|ä¹°å°ç±³è½¦|ç±³ç²‰|ç±³è›†|ç±³çŒ´).*?æ‚²æƒ¨",
                    r"(å°ç±³|é›·å†›).*?(è½¦|æ±½è½¦|SU7|su7).*?(å†æ­»|åˆæ­»|å¤šæ­»|è¿˜è¦æ­»).*?(å¤šå°‘|å‡ ä¸ª|å‡ ä½)",
                    r"(ä¹°|å¼€|å).*?(å°ç±³|é›·å†›).*?(è½¦|æ±½è½¦|SU7|su7).*?(ç­‰æ­»|æ‰¾æ­»|è‡ªæ€|é€å‘½)",
                    r"(å°ç±³|é›·å†›).*?çš„?è½¦.*?(å®³äºº|å®³å‘½|å¤ºå‘½|æ€äºº|ç´¢å‘½|è‡´å‘½|æ®‹|å‘½)",
                    # ç§»åŠ¨æ£ºæ/æµ‹è¯•ç»“æœ
                    r"ç§»åŠ¨(æ£ºæ|ç‚¸å¼¹|å¢“åœ°)", r"æµ‹è¯•ç»“æœ.*?ä¹˜å®¢å…¨éƒ¨ç¢³åŒ–",
                    # å…¬å…³/è´£ä»»/ä¿¡æ¯æ©ç›–è´¨ç–‘
                    r"(å°ç±³|é›·å†›).*?(å…¬å…³|è°è¨€|æ¬ºéª—|å¿½æ‚ |éšç’).*?(è½¦|æ±½è½¦|äº‹æ•…|è½¦ç¥¸)",
                    r"(å‡ºäº‹|è½¦ç¥¸|äº‹æ•…).*?ç†ä¸­å®¢",
                    r"(å°ç±³|é›·å†›).*?(è½¦|æ±½è½¦|SU7|su7).*?(ä¸ä¼š|æ²¡æœ‰).*?(è®¤é”™|é“æ­‰|æ‰¿æ‹…è´£ä»»)",
                    r"(å°ç±³|é›·å†›).*?(è½¦|æ±½è½¦|SU7|su7).*?(å…¬å…³|å‹ä½|æ©ç›–|é®æ©).*?(äº‹æ•…|è½¦ç¥¸|çœŸç›¸)",
                    r"(å‡ºäº‹|è½¦ç¥¸|äº‹æ•…).*?è¿˜.*?(æ´—ç™½|æ´—åœ°|è¾©è§£|å¸®.*?è¯´è¯)",
                    r"(å°ç±³|é›·å†›).*?å‡ºäº†.*?(äº‹|è½¦ç¥¸|äº‹æ•…).*?(èº²|è—|è·‘|é€ƒ|é¿|é—­å˜´)",
                    r"åŒ—äº¬æ‚å˜´ç‹", # æ–°å¢
                    # åŒæ ‡/å¹¸ç¾ä¹ç¥¸
                    r"é—®ç•Œå‡ºäº‹.*?å…¨ç½‘ç¾¤å˜².*?å°ç±³å‡ºäº‹.*?å…¨ç½‘æ´—åœ°",
                    r"å»ºå›½ç¬¬ä¸€ä¾‹è½¦ç¥¸", r"åå™¬ç»ˆä¼šåˆ°æ¥", r"ç¦æŠ¥æ¥å•¦",
                    r"ä¸ºä»€ä¹ˆè¿™æ¬¡çš„ç½‘å‹éƒ½é‚£ä¹ˆ.*?å…‹åˆ¶", # æ–°å¢
                    # å…¶ä»–
                    r"å°ç±³.*?(è½¦|æ±½è½¦|SU7|su7).*?(å¬å›|é€€è´§|é€€æ¬¾|ç»´æƒ)",
                    r"é«˜é€Ÿ.*?(æ¯ç§’|é€Ÿåº¦).*?(30ç±³|31ç±³|32ç±³|33ç±³).*?(æ¿€å…‰é›·è¾¾|æç¤º).*?(å¤±çµ|å¤±æ•ˆ)",
                    r"é›·åœ£çš„æ©æƒ…è¿˜ä¸å®Œ" # æ–°å¢
                ]
            ],
             # --- ç”¨äº _predict_toxicity çš„ç‰¹å¾æ¨¡å¼ ---
            "sarcasm_irony": [
                re.compile(p, flags) for p in [
                    r"å¤ªå¥½äº†å§.*?åªèƒ½è¯´", r"å¤ªä¼Ÿå¤§äº†.*?[ğŸ’çŒ´]", r"[é›·ç±³]å¤§å–„äºº",
                    r"é€†å¤©", r"ä¹°äº†.*?ä¸ä»….*?è¿˜è¦", r"çœŸé‡‘ç™½é“¶.*?(è¦å‘½|æ­»|ä¹°å‘½)",
                    r"[æ˜Ÿæ˜Ÿçœ¼].*?[æ˜Ÿæ˜Ÿçœ¼]", r"åˆ°å¤„.*?åˆ .*?çœŸç›¸", r"å¹çš„.*?ä¸ç¬¦",
                    r"ç²‰ä¸.*?è´¨ç–‘.*?è°©éª‚", r"ç»§ç»­.*?æ´—.*?å§", r"ç¬‘æ–™.*?ä¸å¤Ÿ.*?æ‰’",
                    r"æ´—.*?å¤§åŠ›.*?æ´—", r"çˆ¹åœ°.*?ä¸è¡Œ", r"æ‚å˜´.*?æ‘¸é»‘",
                    r"å…¬å…³.*?é˜´é˜³æ€ªæ°”", r"è°ƒæ€§.*?ä¼ä¸š", r"è¥é”€.*?å¥—è·¯",
                    r"æ™ºé©¾.*?é—®é¢˜", r"[doge].*?[doge]", r"å¹ç‰›.*?ä¸å¯æ€•.*?å¯æ€•çš„æ˜¯",
                    r"åˆ.*?åˆ.*?åˆ", r"å¾€å“ªä¸ªæ–¹å‘.*?ç”©é”…", r"ä¸é”™.*?å”¯ä¸€.*?ç¼ºç‚¹",
                    r"å»ºè®®.*?æœ‰å®¶äºº.*?åˆ«ä¹°", r"åƒ.*?äººè¡€é¦’å¤´", r"ç†ä¸­å®¢",
                    r"æŸå“ç‰Œ.*?å‘åŠ›", r"æ´—åœ°.*?å¤§å†›", r"æ°´å†›.*?å‡ºåŠ¨",
                    r"å¸®.*?æ´—åœ°", r"å¸®.*?è¯´è¯", r"å›æ—‹é•–", r"é£æ°´è½®æµè½¬",
                    r"ç°ä¸–æŠ¥", r"[ç¬‘å“­].*?[ç¬‘å“­]", r"[åƒç“œ].*?[åƒç“œ]",
                    # æ–°å¢
                    r"ç±³è€é¼ .*?é­…åŠ›æ—¶åˆ»", r"å…¨ä¸–ç•Œ.*?é€†è¡Œ",
                    r"é«˜é«˜å…´å…´.*?è¯…å’’", r"å¤§å¼€çœ¼ç•Œ.*?ğŸ™",
                    r"[æ˜Ÿæ˜Ÿçœ¼].*?(è¥é”€|å‰å®³|ç‰›)",
                    r"(ä¸€ä¼šå„¿|åæ­£|ä¸€å®šæ˜¯).*?(è¾…åŠ©é©¾é©¶|NOA|å®šé€Ÿå·¡èˆª|ä¸å…³å°ç±³çš„äº‹|é“è·¯|è½¯ä»¶)", # æ–°å¢
                    r"åˆ°åº•è°å®¶æ‚å˜´æ‚å¾—æœ€ç‹ å•Š", # æ–°å¢
                    r"çŒ´{10,}", r"\[doge\]{5,}", # æ–°å¢å¤§é‡è¡¨æƒ…
                    r"\[å¤§ç¬‘\]{3,}" # æ–°å¢
                ]
            ],
            "death_related": [
                re.compile(p, flags) for p in [
                    r"è¦å‘½", r"æ­»[è€…å]?", r"æ•‘æ´.*?ä¸[åˆ°äº†]", r"é€ƒç”Ÿ.*?ä¸äº†",
                    r"è½¦é—¨.*?æ‰“ä¸å¼€", r"æ•‘æ´».*?æœºä¼š", r"ç”Ÿå‘½.*?å®‰å…¨",
                    r"å…³èµ·æ¥.*?çƒ§", r"å‡ºäººå‘½", r"çœ‹è°æ­»çš„å¿«", r"é”æ­».*?é©¬åŠ›"
                ]
            ],
            "business_criticism": [
                 re.compile(p, flags) for p in [
                    r"å•†ä¸šå®—æ•™", r"èˆ†è®º.*?æŒæ¡", r"æ‚å˜´", r"åˆ .*?(è§†é¢‘|å¸–|è¯„è®º|çœŸç›¸)",
                    r"åŸ‹æ²¡çœŸç›¸", r"é€ƒé¿è´£ä»»", r"è¥é”€.*?(æ´—åœ°|ç»´æƒ)",
                    r"å…¬å…³.*?(å‹åˆ¶|å‹çƒ­åº¦|æ‚å˜´|å¥—è·¯)", # å¢å¼º
                    r"å½¢è±¡.*?æ‰“æŠ˜æ‰£", r"è°ƒæ€§.*?ä¼ä¸š", r"æ™ºé©¾.*?ä¸å¤Ÿæˆç†Ÿ",
                    r"å®‰å…¨æ€§.*?(é—®é¢˜|å ªå¿§|æ²¡æœ‰)", # å¢å¼º
                    r"å‹.*?çœŸç›¸", r"å…¬å…³.*?å¥—è·¯",
                    r"åˆ«äººæ±½è½¦å‘å¸ƒ.*?éƒ½è¢«è¹­å®Œäº†", # æ–°å¢
                    r"æ‹¿å‡ºæ¥å’Œé›·å†›ç›¸æ¯”", # æ–°å¢
                    r"å…¨æ˜¯ä¸€äº›å¤¸å°ç±³é›·å†›çš„", # æ–°å¢
                    r"å®¢è§‚åˆ†æçš„å¤©èŠ±æ¿" # æ–°å¢
                 ]
            ],
            # ç‰¹å®šè¡¨æƒ…ç»„åˆ (ä½œä¸ºç‰¹å¾ï¼Œè¯„åˆ†åœ¨ _predict_toxicity ä¸­å¤„ç†)
            "emoji_combinations": [
                re.compile(p, flags) for p in [
                    r"\[doge\].*?\[doge\]", r"\[åƒç“œ\].*?\[åƒç“œ\]",
                    r"\[æ˜Ÿæ˜Ÿçœ¼\].*?\[æ˜Ÿæ˜Ÿçœ¼\]", r"\[å‘²ç‰™\].*?æ­»",
                    r"\[doge\].*?æ­»", r"\[ç¬‘å“­\].*?\[ç¬‘å“­\]",
                    r"\[æ»‘ç¨½\].*?\[æ»‘ç¨½\]", r"\[doge\].*?é—®é¢˜",
                    r"\[åƒç“œ\].*?äº‹æ•…", r"\[æ˜Ÿæ˜Ÿçœ¼\].*?è½¦ç¥¸",
                    r"ğŸ˜­", r"ğŸ™", r"ğŸ’", r"ğŸµ", r"\[è—ç‹\]", r"\[å¤§ç¬‘\]" # å•ä¸ªå¼ºç›¸å…³è¡¨æƒ…
                ]
            ]
        }

    def _init_special_terms_and_mappings(self):
        """åˆå§‹åŒ–ç‰¹æ®Šæœ¯è¯­ã€æ˜ å°„å’Œè´Ÿé¢è¯æ±‡"""
        # ç‰¹æ®Šå­—ç¬¦/è¡¨æƒ…æ˜ å°„ -> ç”¨äºæ–‡æœ¬é¢„å¤„ç†æˆ–ç›´æ¥ç‰¹å¾æ£€æµ‹
        self.special_chars_map = {
            "å†–": ["ç±³", "å°ç±³"], "M": ["ç±³", "å°ç±³"], "m": ["ç±³", "å°ç±³"],
            "ğŸ’": "å˜²è®½åŠ¨ç‰©", "ğŸµ": "å˜²è®½åŠ¨ç‰©", # å½’ç±»
            "[doge]": "å˜²è®½è¡¨æƒ…", "[åƒç“œ]": "å˜²è®½è¡¨æƒ…", "[æ˜Ÿæ˜Ÿçœ¼]": "å˜²è®½è¡¨æƒ…",
            "[å‘²ç‰™]": "å˜²è®½è¡¨æƒ…", "[ç¬‘å“­]": "å˜²è®½è¡¨æƒ…", "[æ»‘ç¨½]": "å˜²è®½è¡¨æƒ…",
            "[å¤§ç¬‘]": "å˜²è®½è¡¨æƒ…", "[è—ç‹]": "å˜²è®½è¡¨æƒ…",
            "ğŸ™": "ç‰¹æ®Šç¬¦å·", "ğŸ˜­": "ç‰¹æ®Šç¬¦å·",
            "ğŸ–ï¸": "ç‰¹æ®Šç¬¦å·"
        }

        # åä¸ºç›¸å…³ç‰¹æ®Šæœ¯è¯­ (ç”¨äºåŸºç¡€ç›¸å…³æ€§åˆ¤æ–­)
        self.huawei_special_terms = [
            "åä¸º", "é¸¿è’™", "éº’éºŸ", "å¾•å¡", "åä¸ºäº‘", "æµ·æ€", "é¸¿è’™OS", "HMS", "èŠ±ç²‰",
            "ä½™å¤§å˜´", "ä½™æ‰¿ä¸œ", "ä»»æ­£é", "ä»»æ€»", "èŠ¯ç‰‡æ–­ä¾›", "è‡ªä¸»å¯æ§", "å›½äº§æ›¿ä»£",
            "åä¸ºæŠ˜å å±", "åä¸ºå¹³æ¿", "åä¸ºæ‰‹è¡¨", "åä¸ºè·¯ç”±", "åä¸ºæ‰‹ç¯", "åä¸ºè€³æœº",
            "åä¸ºç¬”è®°æœ¬", "åä¸ºéŸ³ç®±", "é—®ç•Œ", "é˜¿ç»´å¡”", "èµ›åŠ›æ–¯", "é¸¿è’™æ™ºè¡Œ",
            "åä¸ºæ™ºé€‰", "æç‹", "æ™ºç•Œ"
        ]
        # å°ç±³ç›¸å…³ç‰¹æ®Šæœ¯è¯­ (ç”¨äºåˆ¤æ–­æ˜¯å¦æåŠç«å“)
        self.xiaomi_special_terms = [
            "å°ç±³", "çº¢ç±³", "MIUI", "ç±³UI", "é›·å†›", "ç±³ç²‰", "SU7", "su7", "å°çˆ±",
            "ç±³å®¶", "æ¾æ¹ƒOS", "Xiaomi"
        ]

        # å°ç±³è´Ÿé¢è¯æ±‡ (ç”¨äºç›´æ¥æ”»å‡»æ£€æµ‹)
        self.xiaomi_negative_terms = [
            "åƒåœ¾", "è¾£é¸¡", "æ¸£", "å±", "ä¸è¡Œ", "åºŸç‰©", "ç±³çŒ´", "ç±³è›†", "é›·å¸ƒæ–¯",
            "çŒ•çŒ´", "ç²—ç²®", "å·ç±³", "å››æ£’", "å†–", "é›·åœ£", "æ²™é›•ç±³", "å·å›½",
            "ç§»åŠ¨æ£ºæ", "æ™ºå•†ç¨", "ç‚¸å¼¹", "åºŸé“", "å¤–è¡Œ", "éª—å­", "å™±å¤´",
            "PPT", "ä¸ä¸­ç”¨", "å±é™©", "äº‹æ•…", "è½¦ç¥¸", "æ­»äº¡", "è‡´æ­»", "è‡ªæ€",
            "é€å‘½", "æ‰¾æ­»", "ç­‰æ­»", "è´´ç‰Œ", "ç»„è£…å‚", "ä¹°åŠ", "é›·ä¸ç¾¤", "è¹­" # å¢å¼º
        ]

        # å˜ä½“è¯æ˜ å°„ (ä¸»è¦ç”¨äºæ–‡æœ¬æ ‡å‡†åŒ–ï¼Œå¯é€‰)
        self.variant_mapping = {
            "ç±³ç²ª": "ç±³ç²‰", "ç±³çŒ´": "ç±³ç²‰", "ç±³è›†": "ç±³ç²‰", "æ²™é›•ç±³": "å°ç±³",
            "ç²—ç²®": "å°ç±³", "å·å›½": "å°ç±³", "å››æ£’": "å°ç±³", "é›·å¸ƒæ–¯": "é›·å†›",
            "å†–": "å°ç±³", "å·ç±³": "å°ç±³", "é¸¿è›™": "åä¸º", "åå­": "åä¸º",
            "ç¼ºèŠ¯æµ·æ€": "æµ·æ€", "å®‰å“é¸¿è’™": "é¸¿è’™", "å¤ªå›ç³»ç»Ÿ": "é¸¿è’™",
            "è½®å­åŠŸ": "æ³•è½®åŠŸ", "è†œè›¤": "æ±Ÿæ³½æ°‘", "å°ç²ªçº¢": "å°ç²‰çº¢",
            "ç²¾èµµ": "ç²¾ç¥ä¸­å›½äºº", "ç¾çˆ¹": "ç¾å›½", "ç²¾ç¾": "ç²¾ç¥ç¾å›½äºº",
            "é«˜è´µç±³": "å°ç±³", "è›™ä¸º": "åä¸º", "é›·åœ£": "é›·å†›"
            # å¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ æ›´å¤š
        }

    def _init_sentiment_analysis_resources(self):
        """åˆå§‹åŒ–æƒ…æ„Ÿåˆ†ææ‰€éœ€èµ„æºï¼ˆè¯å…¸ç­‰ï¼‰"""
        self.positive_words = [
            "å¥½", "æ£’", "å¼º", "èµ", "å‰å®³", "ä¼˜ç§€", "å‡ºè‰²", "ä½³", "è‰¯å¥½", "ç²¾å½©",
            "ç²¾è‰¯", "ç²¾ç¾", "ç²¾è‡´", "ä¼˜è´¨", "å“è¶Š", "æ°å‡º", "å®Œç¾", "ç»ä½³", "è¶…çº§",
            "é¡¶çº§", "ä¸€æµ", "æ»¡æ„", "å–œæ¬¢", "æ”¯æŒ", "æ¨è", "çˆ±", "æœ€çˆ±", "æˆåŠŸ" # å¢åŠ 
        ]
        self.negative_words = [
            "å·®", "çƒ‚", "å¼±", "ç³Ÿ", "å", "åŠ£", "åƒåœ¾", "åºŸ", "ç ´", "æ¬¡",
            "ä½", "è¹©è„š", "ç²—ç³™", "è‰ç‡", "æ•·è¡", "å¤±æœ›", "è®¨åŒ", "æ¨", "æ†", "çƒ¦",
            "ä¸å¥½", "ä¸è¡Œ", "ä¸å€¼", "ä¸æƒ³", "ä¸æƒ³è¦", "ä¸æ¨è", "ä¸æ»¡æ„", "ä¸å–œæ¬¢",
            "åƒåœ¾", "è¾£é¸¡", "æ¸£", "å±", "å¤±è´¥", "å±é™©", "é—®é¢˜", "äº‹æ•…", "è½¦ç¥¸", "æ­»äº¡", # å¢åŠ 
            "æ‚å˜´", "åŒæ ‡", "è¹­", "è´´ç‰Œ", "ç»„è£…", "ä¹°åŠ" # å¢åŠ 
        ]
        self.extreme_markers = [
            "éå¸¸", "å¾ˆ", "å¤ª", "æ", "ç»å¯¹", "çœŸæ˜¯", "ç®€ç›´", "å®Œå…¨", "çœŸçš„", "å½»åº•",
            "æœ€", "è¶…", "ç‰¹", "ç›¸å½“", "ååˆ†", "æ— æ¯”", "æ ¼å¤–", "åˆ†å¤–", "å°¤å…¶",
            "ï¼", "!!", "!!!", "??", "???"
        ]
        self.intensity_markers = {
            "è¿˜è¡Œ": 1, "ä¸€èˆ¬": 1, "å‡‘åˆ": 1, "ä¸é”™": 2, "æŒºå¥½": 2, "è›®å¥½": 2,
            "å¾ˆå¥½": 3, "å¾ˆæ£’": 3, "å¾ˆå¼º": 3, "éå¸¸å¥½": 4, "éå¸¸æ£’": 4, "éå¸¸å¼º": 4,
            "å¤ªå¥½äº†": 5, "å¤ªæ£’äº†": 5, "å¤ªå¼ºäº†": 5, "æå¥½": 6, "ææ£’": 6, "æå¼º": 6,
            "æœ€å¥½": 7, "æœ€æ£’": 7, "æœ€å¼º": 7, "æ— æ•Œ": 8, "å²è¯—": 8, "é€†å¤©": 8,
            "ç¥çº§": 9, "å¤©ä¸‹ç¬¬ä¸€": 9, "å®‡å®™ç¬¬ä¸€": 9
        }

    def _init_detoxify_model(self):
        """åˆå§‹åŒ–Detoxifyæœ‰æ¯’è¨€è®ºæ£€æµ‹æ¨¡å‹"""
        # ... (ä¹‹å‰çš„DetoxifyåŠ è½½é€»è¾‘ä¿æŒä¸å˜) ...
        try:
            import torch
            from transformers import AutoModelForSequenceClassification, AutoTokenizer
            import os

            os.environ['HF_DATASETS_OFFLINE'] = '1'
            os.environ['TRANSFORMERS_OFFLINE'] = '1'

            # å°è¯•ä¸åŒçš„å¯èƒ½è·¯å¾„
            potential_paths = [
                os.path.join(os.path.dirname(__file__), "model", "toxic_original-c1212f89.ckpt"),
                os.path.join(os.path.dirname(__file__), "toxic_original-c1212f89.ckpt"), # å¦‚æœåœ¨æ ¹ç›®å½•
                "toxic_original-c1212f89.ckpt" # ç›´æ¥æ–‡ä»¶å
            ]

            local_model_path = None
            for path in potential_paths:
                if os.path.exists(path):
                    local_model_path = path
                    break

            if local_model_path:
                self.logger.info(f"ä½¿ç”¨æœ¬åœ°Detoxifyæ¨¡å‹æ–‡ä»¶: {local_model_path}")
                try:
                    # ç›´æ¥åŠ è½½æ¨¡å‹çŠ¶æ€å­—å…¸
                    checkpoint = torch.load(local_model_path, map_location=torch.device('cpu'))

                    # åˆ›å»ºç®€å•é¢„æµ‹å‡½æ•°
                    def predict_fn(text):
                        # è¿™é‡Œæˆ‘ä»¬åªæ˜¯è¿”å›ä¸€ä¸ªåŸºæœ¬çš„é¢„æµ‹ç»“æœ
                        # è¿™æ˜¯ä¸€ä¸ªæ¨¡æ‹Ÿï¼Œå› ä¸ºæˆ‘ä»¬æ²¡æœ‰åŠ è½½å®é™…çš„æ¨¡å‹ç»“æ„
                        # å¯ä»¥æ ¹æ®æ–‡æœ¬å†…å®¹åšä¸€äº›ç®€å•çš„å¯å‘å¼åˆ¤æ–­
                        mock_scores = {
                            "toxic": 0.1, "severe_toxic": 0.05, "obscene": 0.1,
                            "threat": 0.02, "insult": 0.1, "identity_hate": 0.01
                        }
                        # ç®€å•çš„å¯å‘å¼: å¦‚æœåŒ…å«è´Ÿé¢è¯æ±‡ï¼Œæé«˜toxic/insultåˆ†æ•°
                        if any(neg_word in text for neg_word in self.negative_words):
                            mock_scores["toxic"] = min(0.9, mock_scores["toxic"] + 0.4)
                            mock_scores["insult"] = min(0.9, mock_scores["insult"] + 0.3)
                        if "æ­»" in text or "æ€" in text:
                             mock_scores["threat"] = min(0.9, mock_scores["threat"] + 0.6)
                             mock_scores["severe_toxic"] = min(0.9, mock_scores["severe_toxic"] + 0.5)
                        return mock_scores

                    class SimpleDetoxify:
                        def predict(self, text):
                            return predict_fn(text)

                    self.detoxify_model = SimpleDetoxify()
                    self.detoxify_available = True
                    self.logger.info("æˆåŠŸåŠ è½½(æ¨¡æ‹Ÿ)Detoxifyæ¨¡å‹")
                except Exception as e:
                    self.logger.error(f"åŠ è½½æœ¬åœ°Detoxifyæ¨¡å‹çŠ¶æ€å­—å…¸å¤±è´¥: {e}")
                    self.detoxify_available = False
            else:
                self.logger.warning("è­¦å‘Š: æœªæ‰¾åˆ°æœ¬åœ°Detoxifyæ¨¡å‹æ–‡ä»¶ã€‚DetoxifyåŠŸèƒ½å°†ä¸å¯ç”¨ã€‚")
                self.detoxify_available = False

        except ImportError:
             self.logger.warning("è­¦å‘Š: ç¼ºå°‘ torch æˆ– transformers åº“ï¼Œæ— æ³•åŠ è½½Detoxifyæ¨¡å‹ã€‚")
             self.detoxify_available = False
        except Exception as e:
            self.logger.error(f"åˆå§‹åŒ–Detoxifyæ¨¡å‹æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
            self.detoxify_available = False

        # è®¾ç½®æ¯’æ€§é˜ˆå€¼ - æå¤§åœ°é™ä½é˜ˆå€¼ä»¥æœ€å¤§åŒ–å¬å›ç‡
        self.toxicity_thresholds = {
            "toxic": 0.15,           # æä½
            "severe_toxic": 0.10,    # æä½
            "obscene": 0.15,         # æä½
            "threat": 0.10,          # æä½
            "insult": 0.15,          # æä½
            "identity_hate": 0.10     # æä½
        }

    def _preprocess_text(self, text):
        """é¢„å¤„ç†æ–‡æœ¬ï¼Œå¤„ç†ç‰¹æ®Šå­—ç¬¦å’Œè¡¨æƒ…"""
        if not text:
            return text
        processed = text
        # ç®€å•å¤„ç†ï¼Œä¸»è¦ç”¨äºåç»­åŒ¹é…ï¼Œæ›´å¤æ‚çš„æ ‡å‡†åŒ–å¯ä»¥åŠ å…¥variant_mapping
        # ç§»é™¤æˆ–æ›¿æ¢ä¸€äº›å¯èƒ½å½±å“æ­£åˆ™åŒ¹é…çš„ç‰¹æ®Šæ§åˆ¶å­—ç¬¦ï¼ˆå¦‚æœéœ€è¦ï¼‰
        # ...
        return processed.lower() # è½¬æ¢ä¸ºå°å†™ï¼Œé…åˆ IGNORECASE

    def _check_variant_patterns(self, content):
        """æ£€æŸ¥å†…å®¹ä¸­çš„å˜ä½“è¯å’Œç‰¹æ®Šç¬¦å·/è¡¨æƒ… (ç®€åŒ–ç‰ˆï¼Œä¸»è¦ç”¨äºè¯„åˆ†)"""
        if not content:
            return 0, [], []

        processed_content = self._preprocess_text(content)
        variant_score = 0
        detected_variants = [] # ç”¨äºè®°å½•æ£€æµ‹åˆ°çš„å…·ä½“å˜ä½“æˆ–ç¬¦å·

        # æ£€æŸ¥ç‰¹æ®Šå­—ç¬¦/è¡¨æƒ…æ˜ å°„è¡¨ä¸­çš„é¡¹
        for char, category in self.special_chars_map.items():
            count = processed_content.count(char)
            if count > 0:
                # æ ¹æ®ç±»åˆ«å’Œæ•°é‡ç»™åˆ†
                if "å˜²è®½" in category:
                    variant_score += count * 0.3 # æ¯ä¸ªå˜²è®½ç¬¦å·/è¡¨æƒ… 0.3åˆ† (é™ä½)
                elif "åŠ¨ç‰©" in category:
                     variant_score += count * 0.8 # åŠ¨ç‰©è°éŸ³åˆ†æ•°æ›´é«˜ (ä¿æŒ)
                else:
                    variant_score += count * 0.2 # å…¶ä»–ç‰¹æ®Šç¬¦å·åˆ†æ•°è¾ƒä½ (ä¿æŒ)
                detected_variants.append(f"{category}: {char} (x{count})")
                # å¯¹å¤§é‡é‡å¤çš„è¡¨æƒ…åŠ é‡æ‰£åˆ†
                if count >= 5 and "è¡¨æƒ…" in category:
                    variant_score += 1.5
                    detected_variants.append(f"å¤§é‡é‡å¤è¡¨æƒ…: {char}")
                elif count >= 10 and char == 'ğŸ’': # ç‰¹åˆ«é’ˆå¯¹å¤§é‡çŒ´å­è¡¨æƒ…
                    variant_score += 2.5
                    detected_variants.append(f"æå¤§é‡çŒ´å­è¡¨æƒ…: {char}")

        # æ£€æŸ¥å˜ä½“è¯ (å¯é€‰ï¼Œå¦‚æœéœ€è¦æ›´ç²¾ç¡®çš„æ ‡å‡†åŒ–å’Œæ£€æµ‹)
        # for standard, variants in self.variant_mapping.items():
        #     for variant in variants:
        #         if variant in processed_content:
        #             variant_score += 0.5 # æ¯ä¸ªå˜ä½“è¯åŠ åˆ†
        #             detected_variants.append(f"å˜ä½“è¯: {variant} -> {standard}")

        # ç®€å•ç»„åˆåŠ æˆ
        if len(detected_variants) >= 3:
            variant_score *= 1.2

        return variant_score, detected_variants, [] # ä¸å†è¿”å› pattern

    def _normalize_text(self, content):
        """(å¯é€‰)æ ‡å‡†åŒ–æ–‡æœ¬ï¼Œæ›¿æ¢å˜ä½“è¯ä¸ºæ ‡å‡†å½¢å¼"""
        if not content: return content
        normalized = content
        # for key, variants in self.variant_mapping.items():
        #     for variant in variants:
        #         normalized = normalized.replace(variant, key)
        # ...
        return normalized

    def _analyze_emotional_intensity(self, content):
        """åˆ†æè¯„è®ºæƒ…æ„Ÿå¼ºåº¦ï¼ˆåŸºç¡€ç‰ˆï¼‰"""
        if not content: return 0
        sentiment_score = 0
        processed_content = self._preprocess_text(content)

        # æ­£é¢è¯
        positive_count = sum(word in processed_content for word in self.positive_words)
        sentiment_score += positive_count * 0.8 # é™ä½æ­£é¢è¯å½±å“

        # è´Ÿé¢è¯
        negative_count = sum(word in processed_content for word in self.negative_words)
        sentiment_score += negative_count * 1.8 # æé«˜è´Ÿé¢è¯å½±å“

        # æç«¯æ ‡è®°è¯
        extreme_count = sum(marker in processed_content for marker in self.extreme_markers)
        sentiment_score += extreme_count * 0.6

        # å¼ºåº¦è¯
        for marker, score in self.intensity_markers.items():
            if marker in processed_content:
                sentiment_score += score * 0.4

        # æ ‡ç‚¹
        exclamation_count = processed_content.count('!') + processed_content.count('ï¼')
        sentiment_score += exclamation_count * 0.5
        question_count = processed_content.count('?') + processed_content.count('ï¼Ÿ')
        sentiment_score += question_count * 0.3

        # é•¿åº¦å› å­ (å½±å“å‡å°)
        length_factor = min(len(processed_content) / 100, 1.5)
        sentiment_score += length_factor

        return sentiment_score

    def enhanced_sentiment_analysis(self, content):
        """å¢å¼ºç‰ˆæƒ…æ„Ÿåˆ†æï¼Œç»“åˆåŸºç¡€åˆ†æå’Œè®½åˆºæ£€æµ‹"""
        if not content: return 0

        # åŸºç¡€æƒ…æ„Ÿåˆ†æ
        base_score = self._analyze_emotional_intensity(content)

        # æ£€æµ‹è®½åˆºå’Œåè®½
        sarcasm_score = self._detect_sarcasm(content)

        # æ£€æµ‹æƒ…æ„Ÿå†²çªï¼ˆè¡¨é¢ç§¯æä½†å®é™…æ¶ˆæï¼‰
        conflict_score = self._detect_sentiment_conflict(content)

        # æ£€æµ‹è¡¨æƒ…ç¬¦å·æƒ…æ„Ÿ
        emoji_score = self._analyze_emoji_sentiment(content)

        # ç»¼åˆè¯„åˆ†ï¼Œè®½åˆºå’Œæƒ…æ„Ÿå†²çªä¼šæ˜¾è‘—æé«˜æƒ…æ„Ÿå¼ºåº¦
        final_score = base_score + (sarcasm_score * 2.0) + (conflict_score * 1.5) + (emoji_score * 1.0)

        return final_score

    def advanced_sentiment_analysis(self, content):
        """é«˜çº§æƒ…æ„Ÿåˆ†æ"""
        if not content:
            return 0

        # åŸºç¡€æƒ…æ„Ÿåˆ†æ
        base_score = self.enhanced_sentiment_analysis(content)

        # æ·»åŠ æ›´å¤šæƒ…æ„Ÿç‰¹å¾
        additional_score = 0

        # 1. æ£€æµ‹æç«¯å¯¹æ¯”
        extreme_contrast_score = self._detect_extreme_contrast(content)
        additional_score += extreme_contrast_score * 0.8

        # 2. æ£€æµ‹è¿‡åº¦å¤¸å¼µ
        exaggeration_score = self._detect_exaggeration(content)
        additional_score += exaggeration_score * 0.7

        # 3. æ£€æµ‹æƒ…æ„Ÿå¼ºåº¦çªå˜
        emotion_shift_score = self._detect_emotion_shift(content)
        additional_score += emotion_shift_score * 0.6

        # 4. æ£€æµ‹é‡å¤å¼ºè°ƒ
        repetitive_emphasis_score = self._detect_repetitive_emphasis(content)
        additional_score += repetitive_emphasis_score * 0.5

        # ç»¼åˆè¯„åˆ†ï¼Œä½†è®¾ç½®ä¸Šé™ä»¥é¿å…è¿‡åº¦å½±å“
        final_score = min(base_score + additional_score, 10.0)

        return final_score

    def _detect_extreme_contrast(self, content):
        """æ£€æµ‹æç«¯å¯¹æ¯”"""
        score = 0

        # æ£€æµ‹æç«¯å¯¹æ¯”æ¨¡å¼
        contrast_patterns = [
            r"(åä¸º|é¸¿è’™).*?(\S+).*?(å°ç±³|å®‰å“).*?(\S+ä¸äº†|\S+åƒåœ¾|\S+æ¸£|\S+å·®)",
            r"(å°ç±³|å®‰å“).*?(\S+ä¸äº†|\S+åƒåœ¾|\S+æ¸£|\S+å·®).*?(åä¸º|é¸¿è’™).*?(\S+)",
            r"(åä¸º|é¸¿è’™).*?(å¸æ‰“|ç¢°å‹|ç§’æ€|å®Œçˆ†).*?(å°ç±³|å®‰å“|è‹¹æœ|iOS)",
            r"(å°ç±³|å®‰å“|è‹¹æœ|iOS).*?(ä¸å¦‚|æ¯”ä¸ä¸Š|å·®è¿œäº†).*?(åä¸º|é¸¿è’™)"
        ]

        for pattern in contrast_patterns:
            if re.search(pattern, content):
                score += 1.0

        # æ£€æµ‹æç«¯å½¢å®¹è¯å¯¹æ¯”
        positive_adj = ["æœ€å¼º", "æ— æ•Œ", "é¡¶çº§", "ä¸€æµ", "å“è¶Š", "å®Œç¾", "è¶…çº§", "æ——èˆ°"]
        negative_adj = ["åƒåœ¾", "æ¸£", "å·®", "çƒ‚", "å¼±", "åºŸ", "ä¸è¡Œ", "å±±å¯¨"]

        has_positive = any(adj in content for adj in positive_adj)
        has_negative = any(adj in content for adj in negative_adj)

        if has_positive and has_negative:
            score += 1.0

        return min(score, 2.0)  # æœ€é«˜2åˆ†

    def _detect_exaggeration(self, content):
        """æ£€æµ‹è¿‡åº¦å¤¸å¼µ"""
        score = 0

        # æ£€æµ‹å¤¸å¼µè¯æ±‡
        exaggeration_words = ["ç»å¯¹", "å¿…ç„¶", "è‚¯å®š", "ä¸€å®š", "æ°¸è¿œ", "ä»æ¥", "å²ä¸Š", "å‰æ‰€æœªæœ‰",
                             "é¡¶è¦†", "é©å‘½æ€§", "åˆ’æ—¶ä»£", "æ”¹å˜ä¸–ç•Œ", "æ— äººèƒ½æ•Œ", "æ— å¯åŒ¹æ•µ"]

        for word in exaggeration_words:
            if word in content:
                score += 0.3

        # æ£€æµ‹æ•°å­—å¤¸å¼µ
        number_patterns = [
            r"(\d+)å¹´.*?é¢†å…ˆ",
            r"é¢†å…ˆ.*?(\d+)å¹´",
            r"(\d+)å€.*?(æ€§èƒ½|é€Ÿåº¦|æ•ˆç‡)",
            r"(æ€§èƒ½|é€Ÿåº¦|æ•ˆç‡).*?(\d+)å€"
        ]

        for pattern in number_patterns:
            matches = re.findall(pattern, content)
            for match in matches:
                # æå–æ•°å­—
                numbers = [int(re.sub(r'\D', '', num)) for num in match if re.sub(r'\D', '', num)]
                for num in numbers:
                    if num > 5:  # å¦‚æœæ•°å­—å¤§äº5ï¼Œè®¤ä¸ºå¯èƒ½æ˜¯å¤¸å¼µ
                        score += 0.5

        return min(score, 2.0)  # æœ€é«˜2åˆ†

    def _detect_emotion_shift(self, content):
        """æ£€æµ‹æƒ…æ„Ÿå¼ºåº¦çªå˜"""
        score = 0

        # å°†å†…å®¹åˆ†æˆå¥å­
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ.!?]', content)
        if len(sentences) < 2:
            return 0

        # è®¡ç®—æ¯ä¸ªå¥å­çš„æƒ…æ„Ÿå¼ºåº¦
        sentence_scores = []
        for sentence in sentences:
            if len(sentence.strip()) > 0:
                sentence_score = self._analyze_emotional_intensity(sentence)
                sentence_scores.append(sentence_score)

        # è®¡ç®—æƒ…æ„Ÿå¼ºåº¦å˜åŒ–
        if len(sentence_scores) >= 2:
            shifts = [abs(sentence_scores[i] - sentence_scores[i-1]) for i in range(1, len(sentence_scores))]
            max_shift = max(shifts) if shifts else 0

            # å¦‚æœæƒ…æ„Ÿå¼ºåº¦å˜åŒ–å¤§ï¼Œå¯èƒ½æ˜¯æƒ…æ„Ÿçªå˜
            if max_shift > 3:
                score += 1.0
            elif max_shift > 2:
                score += 0.7
            elif max_shift > 1:
                score += 0.3

        return min(score, 1.5)  # æœ€é«˜1.5åˆ†

    def _detect_repetitive_emphasis(self, content):
        """æ£€æµ‹é‡å¤å¼ºè°ƒ"""
        score = 0

        # æ£€æµ‹é‡å¤æ ‡ç‚¹
        punctuation_patterns = [
            r"!{2,}",
            r"\?{2,}",
            r"ï¼{2,}",
            r"ï¼Ÿ{2,}"
        ]

        for pattern in punctuation_patterns:
            matches = re.findall(pattern, content)
            score += len(matches) * 0.3

        # æ£€æµ‹é‡å¤è¯è¯­
        words = re.findall(r'\w+', content)
        word_counts = {}
        for word in words:
            if len(word) >= 2:  # åªè€ƒè™‘é•¿åº¦å¤§äºç­‰äº2çš„è¯
                word_counts[word] = word_counts.get(word, 0) + 1

        # ç»Ÿè®¡é‡å¤æ¬¡æ•°å¤§äº2çš„è¯
        repeated_words = [word for word, count in word_counts.items() if count > 2]
        score += len(repeated_words) * 0.4

        # æ£€æµ‹é‡å¤å¥å¼
        sentence_patterns = [
            r"([\w\s]{5,})[,ï¼Œ].*?\1",  # æ£€æµ‹é‡å¤çŸ­è¯­
            r"([\w\s]{3,})[,ï¼Œ].*?\1[,ï¼Œ].*?\1"  # æ£€æµ‹ä¸‰æ¬¡é‡å¤
        ]

        for pattern in sentence_patterns:
            matches = re.findall(pattern, content)
            score += len(matches) * 0.5

        return min(score, 1.5)  # æœ€é«˜1.5åˆ†

    def analyze_user_behavior(self, mid, comments):
        """
        åˆ†æç”¨æˆ·è¡Œä¸ºæ¨¡å¼

        Args:
            mid (int): ç”¨æˆ·ID
            comments (list): ç”¨æˆ·çš„è¯„è®ºåˆ—è¡¨

        Returns:
            tuple: (fanatic_score, user_stats) æç«¯ç²‰ä¸å¯èƒ½æ€§åˆ†æ•°å’Œç”¨æˆ·ç»Ÿè®¡ä¿¡æ¯
        """
        # åˆå§‹åŒ–ç”¨æˆ·ç»Ÿè®¡ä¿¡æ¯
        user_stats = {
            "total_comments": 0,
            "extreme_comments": 0,
            "huawei_mentions": 0,
            "xiaomi_mentions": 0,
            "negative_xiaomi": 0,
            "positive_huawei": 0,
            "sarcasm_count": 0,
            "brand_bias_score": 0,
            "comment_pattern": {}
        }

        if not comments:
            return 0, user_stats

        # åˆ†æç”¨æˆ·çš„æ‰€æœ‰è¯„è®º
        for comment in comments:
            content = ""
            if isinstance(comment.get("content"), dict):
                content = comment["content"].get("message", "")
            elif isinstance(comment.get("content"), str):
                content = comment["content"]

            if not content:
                continue

            user_stats["total_comments"] += 1

            # æ£€æµ‹æç«¯è¨€è®º
            is_extreme, detection_result = self.enhanced_extreme_fan_detection(content)
            if is_extreme:
                user_stats["extreme_comments"] += 1

                # è®°å½•æç«¯ç±»å‹
                extreme_types = detection_result.get("extreme_types", [])
                for extreme_type in extreme_types:
                    user_stats["comment_pattern"][extreme_type] = user_stats["comment_pattern"].get(extreme_type, 0) + 1

            # ç»Ÿè®¡å“ç‰ŒæåŠ
            if any(term in content.lower() for term in self.huawei_special_terms):
                user_stats["huawei_mentions"] += 1
                # æ£€æµ‹å¯¹åä¸ºçš„æ­£é¢æƒ…æ„Ÿ
                sentiment = self._analyze_emotional_intensity(content)
                if sentiment > 0:
                    user_stats["positive_huawei"] += 1

            if any(term in content.lower() for term in self.xiaomi_special_terms):
                user_stats["xiaomi_mentions"] += 1
                # æ£€æµ‹å¯¹å°ç±³çš„è´Ÿé¢æƒ…æ„Ÿ
                sentiment = self._analyze_emotional_intensity(content)
                if sentiment < 0:
                    user_stats["negative_xiaomi"] += 1

            # æ£€æµ‹è®½åˆº
            sarcasm_score = self._detect_sarcasm(content)
            if sarcasm_score > 0.5:
                user_stats["sarcasm_count"] += 1

        # è®¡ç®—æç«¯ç²‰ä¸å¯èƒ½æ€§åˆ†æ•°
        fanatic_score = 0
        if user_stats["total_comments"] > 0:
            # æç«¯è¨€è®ºæ¯”ä¾‹
            extreme_ratio = user_stats["extreme_comments"] / user_stats["total_comments"]
            user_stats["extreme_ratio"] = extreme_ratio

            # å“ç‰Œåå‘æ€§
            brand_bias = 0
            if user_stats["huawei_mentions"] > 0 and user_stats["xiaomi_mentions"] > 0:
                huawei_positive_ratio = user_stats["positive_huawei"] / user_stats["huawei_mentions"]
                xiaomi_negative_ratio = user_stats["negative_xiaomi"] / user_stats["xiaomi_mentions"]
                brand_bias = huawei_positive_ratio + xiaomi_negative_ratio
                user_stats["brand_bias_score"] = brand_bias

            # è®½åˆºæ¯”ä¾‹
            sarcasm_ratio = user_stats["sarcasm_count"] / user_stats["total_comments"]
            user_stats["sarcasm_ratio"] = sarcasm_ratio

            # ç»¼åˆè¯„åˆ†
            fanatic_score = extreme_ratio * 0.4 + brand_bias * 0.4 + sarcasm_ratio * 0.2

            # å¦‚æœæœ‰æ˜æ˜¾çš„æç«¯ç±»å‹åå¥½ï¼Œå¢åŠ åˆ†æ•°
            pattern_bias = 0
            if user_stats["comment_pattern"]:
                # æ£€æŸ¥æ˜¯å¦æœ‰ç‰¹å®šç±»å‹çš„æç«¯è¨€è®ºå‡ºç°é¢‘ç‡è¾ƒé«˜
                total_patterns = sum(user_stats["comment_pattern"].values())
                for pattern, count in user_stats["comment_pattern"].items():
                    if count / total_patterns > 0.5:  # å¦‚æœæŸä¸€ç±»å‹å æ¯”è¶…è¿‡50%
                        pattern_bias = 0.2
                        break

            fanatic_score += pattern_bias

        return fanatic_score, user_stats

    def update_detection_model(self, false_positives, false_negatives):
        """æ ¹æ®è¯¯åˆ¤æ ·æœ¬æ›´æ–°æ£€æµ‹æ¨¡å‹"""
        # åˆ†æè¯¯åˆ¤æ ·æœ¬
        fp_features = self._extract_features_from_samples(false_positives)
        fn_features = self._extract_features_from_samples(false_negatives)

        # è°ƒæ•´ç‰¹å¾æƒé‡
        for feature, count in fp_features.items():
            if feature in self.feature_weights:
                # é™ä½å¯¼è‡´è¯¯åˆ¤çš„ç‰¹å¾æƒé‡
                self.feature_weights[feature] *= max(0.9, 1 - (count / len(false_positives) * 0.2))
                self.logger.info(f"é™ä½ç‰¹å¾æƒé‡: {feature} -> {self.feature_weights[feature]:.2f}")

        for feature, count in fn_features.items():
            if feature in self.feature_weights:
                # æé«˜æ¼åˆ¤çš„ç‰¹å¾æƒé‡
                self.feature_weights[feature] *= min(1.1, 1 + (count / len(false_negatives) * 0.2))
                self.logger.info(f"æé«˜ç‰¹å¾æƒé‡: {feature} -> {self.feature_weights[feature]:.2f}")

        # æ›´æ–°é˜ˆå€¼
        if false_positives and false_negatives:
            fp_confidences = [sample.get("detection_result", {}).get("confidence", 0) for sample in false_positives]
            fn_confidences = [sample.get("detection_result", {}).get("confidence", 0) for sample in false_negatives]

            avg_fp_confidence = sum(fp_confidences) / len(fp_confidences)
            avg_fn_confidence = sum(fn_confidences) / len(fn_confidences)

            # è°ƒæ•´é˜ˆå€¼ï¼Œåœ¨è¯¯åˆ¤å’Œæ¼åˆ¤ä¹‹é—´æ‰¾å¹³è¡¡ç‚¹
            if avg_fp_confidence > 0 and avg_fn_confidence > 0:
                new_threshold = (avg_fp_confidence + avg_fn_confidence) / 2
                old_threshold = self.detection_threshold
                self.detection_threshold = new_threshold
                self.logger.info(f"æ›´æ–°æ£€æµ‹é˜ˆå€¼: {old_threshold:.2f} -> {new_threshold:.2f}")

        return {
            "feature_weights": self.feature_weights,
            "detection_threshold": self.detection_threshold
        }

    def _extract_features_from_samples(self, samples):
        """ä»æ ·æœ¬ä¸­æå–ç‰¹å¾"""
        feature_counts = {}

        for sample in samples:
            content = sample.get("content", "")
            detection_result = sample.get("detection_result", {})
            matched_patterns = detection_result.get("matched_patterns", {})

            # ç»Ÿè®¡åŒ¹é…æ¨¡å¼
            for pattern_type in matched_patterns:
                feature_counts[pattern_type] = feature_counts.get(pattern_type, 0) + 1

            # æ£€æŸ¥æ˜¯å¦åŒ…å«ç‰¹å®šå…³é”®è¯
            for term in self.huawei_special_terms:
                if term in content.lower():
                    feature_counts["huawei_term"] = feature_counts.get("huawei_term", 0) + 1
                    break

            for term in self.xiaomi_special_terms:
                if term in content.lower():
                    feature_counts["xiaomi_term"] = feature_counts.get("xiaomi_term", 0) + 1
                    break

            # æ£€æŸ¥æƒ…æ„Ÿå¼ºåº¦
            sentiment_score = self._analyze_emotional_intensity(content)
            if sentiment_score > 3:
                feature_counts["high_sentiment"] = feature_counts.get("high_sentiment", 0) + 1

            # æ£€æŸ¥è®½åˆº
            sarcasm_score = self._detect_sarcasm(content)
            if sarcasm_score > 0.5:
                feature_counts["sarcasm"] = feature_counts.get("sarcasm", 0) + 1

        return feature_counts

    def _detect_sarcasm(self, content):
        """æ£€æµ‹è®½åˆºå’Œåè®½"""
        if not content: return 0
        sarcasm_score = 0
        processed_content = self._preprocess_text(content)

        # ä½¿ç”¨ä¼˜åŒ–åçš„è®½åˆº/é˜´é˜³æ€ªæ°”ç›¸å…³æ­£åˆ™è¡¨è¾¾å¼
        sarcasm_patterns = [
            r"çœŸ(æ˜¯|çš„)?(å¥½|æ£’|å¼º|å‰å®³).*?[å‘µå“ˆå˜»]",
            r"å‰å®³äº†.*?æˆ‘çš„å“¥",
            r"ä¸æ„§æ˜¯.*?",
            r"å°±è¿™.*?\?",
            r"å¤ª(å‰å®³|å¼º|æ£’)äº†å§.*?\[doge\]",
            r"å¯çœŸæ˜¯.*?(ç‰›|å‰å®³|å¼º)",
            r"ç¬‘æ­».*?äºº",
            r"æœ‰ç‚¹.*?(æ„æ€|ä¸œè¥¿)",
            r"æˆ‘ä»¬.*?é…å—",
            r"è¿™æ³¢.*?æ“ä½œ",
            r"é«˜ç«¯.*?å¤§æ°”",
            r"ä¸€æ•´ä¸ª.*?ç¦»è°±",
            r"ç»äº†.*?",
            r"ç‰›å•Š.*?ç‰›å•Š",
            r"é›·å¸ƒæ–¯.*?(åˆ|å†|è¿˜).*?(èµ¢|æˆåŠŸ|èƒœåˆ©)",
            r"å°ç±³.*?(åˆ|å†|è¿˜).*?(èµ¢|æˆåŠŸ|èƒœåˆ©)",
            r"é›·å†›.*?(åˆ|å†|è¿˜).*?(èµ¢|æˆåŠŸ|èƒœåˆ©)",
            r"(é›·å†›|å°ç±³).*?èµ¢éº»äº†",
            r"(é›·å†›|å°ç±³).*?èµ¢(éº»|å—¨|çˆ†)",
            r"(é›·å†›|å°ç±³).*?å®‡å®™ç¬¬ä¸€",
            r"(é›·å†›|å°ç±³).*?å®‡å®™æ— æ•Œ",
            r"(é›·å†›|å°ç±³).*?æ°¸è¿œçš„ç¥"
        ]

        # æ£€æŸ¥è®½åˆºæ¨¡å¼
        for pattern in sarcasm_patterns:
            if re.search(pattern, processed_content, re.IGNORECASE):
                sarcasm_score += 0.5

        # æ£€æŸ¥ç‰¹å®šè¡¨æƒ…ç»„åˆ
        sarcasm_emojis = ["[doge]", "[æ»‘ç¨½]", "[åƒç“œ]", "[ç¬‘å“­]", "[é˜´é™©]", "ğŸ¶", "ğŸ’", "ğŸ¤¡"]
        for emoji in sarcasm_emojis:
            if emoji in content:
                sarcasm_score += 0.3

        # æ£€æŸ¥ç‰¹å®šæ ‡ç‚¹ç»„åˆ
        if "???" in content or "ï¼Ÿï¼Ÿï¼Ÿ" in content:
            sarcasm_score += 0.3
        if "!!!" in content or "ï¼ï¼ï¼" in content:
            sarcasm_score += 0.2

        # ä¸Šé™ä¸º2.0
        return min(sarcasm_score, 2.0)

    def _detect_sentiment_conflict(self, content):
        """æ£€æµ‹æƒ…æ„Ÿå†²çªï¼ˆè¡¨é¢ç§¯æä½†å®é™…æ¶ˆæï¼‰"""
        if not content: return 0
        conflict_score = 0
        processed_content = self._preprocess_text(content)

        # è®¡ç®—æ­£é¢è¯å’Œè´Ÿé¢è¯çš„æ•°é‡
        positive_count = sum(word in processed_content for word in self.positive_words)
        negative_count = sum(word in processed_content for word in self.negative_words)

        # å¦‚æœåŒæ—¶åŒ…å«è¾ƒå¤šæ­£é¢è¯å’Œè´Ÿé¢è¯ï¼Œå¯èƒ½å­˜åœ¨æƒ…æ„Ÿå†²çª
        if positive_count >= 2 and negative_count >= 1:
            conflict_score += 0.5 * min(positive_count, negative_count)

        # æ£€æŸ¥ç‰¹å®šçš„æƒ…æ„Ÿå†²çªæ¨¡å¼
        conflict_patterns = [
            r"(å¥½|æ£’|å¼º|å‰å®³).*?(ä½†æ˜¯|å¯æ˜¯|ç„¶è€Œ|ä¸è¿‡)",
            r"(ä½†æ˜¯|å¯æ˜¯|ç„¶è€Œ|ä¸è¿‡).*?(å¥½|æ£’|å¼º|å‰å®³)",
            r"è™½ç„¶.*?ä½†æ˜¯",
            r"çœ‹èµ·æ¥.*?å®é™…ä¸Š",
            r"è¡¨é¢ä¸Š.*?å…¶å®"
        ]

        for pattern in conflict_patterns:
            if re.search(pattern, processed_content):
                conflict_score += 0.5

        # ä¸Šé™ä¸º2.0
        return min(conflict_score, 2.0)

    def _analyze_emoji_sentiment(self, content):
        """åˆ†æè¡¨æƒ…ç¬¦å·çš„æƒ…æ„Ÿ"""
        if not content: return 0

        emoji_score = 0

        # Bç«™ç‰¹æœ‰è¡¨æƒ…çš„æƒ…æ„Ÿæ˜ å°„
        emoji_sentiment = {
            "[doge]": 0.8,  # è®½åˆº
            "[åƒç“œ]": 0.5,  # çœ‹çƒ­é—¹
            "[ç¬‘å“­]": 0.7,  # å˜²ç¬‘
            "[æ»‘ç¨½]": 0.9,  # è®½åˆº
            "[é˜´é™©]": 1.0,  # è´Ÿé¢
            "[ç”Ÿæ°”]": 1.0,  # è´Ÿé¢
            "[å§”å±ˆ]": 0.6,  # è´Ÿé¢
            "[æ‚è„¸]": 0.5,  # å°´å°¬
            "[æ€è€ƒ]": 0.3,  # ä¸­æ€§
            "[ç–‘æƒ‘]": 0.4,  # ä¸­æ€§åè´Ÿ
            "[å–œæ¬¢]": -0.5,  # æ­£é¢
            "[ç¬‘]": -0.3,  # æ­£é¢
            "[æ‰“call]": -0.7,  # æ­£é¢
            "[é¼“æŒ]": -0.6,  # æ­£é¢
            "[å¤§å“­]": 0.8,  # è´Ÿé¢
            "[å·ç¬‘]": 0.6   # è®½åˆº
        }

        # ç»Ÿè®¡è¡¨æƒ…å‡ºç°æ¬¡æ•°åŠå…¶æƒ…æ„Ÿå¾—åˆ†
        for emoji, sentiment in emoji_sentiment.items():
            count = content.count(emoji)
            if count > 0:
                # å¤šä¸ªç›¸åŒè¡¨æƒ…ä¼šå¢å¼ºæƒ…æ„Ÿ
                emoji_score += sentiment * min(count, 3)  # æœ€å¤šè®¡ç®—3ä¸ªç›¸åŒè¡¨æƒ…

        # æ£€æŸ¥Unicodeè¡¨æƒ…ç¬¦å·
        unicode_emojis = re.findall(r'[\U0001F600-\U0001F64F\U0001F300-\U0001F5FF\U0001F680-\U0001F6FF\U0001F700-\U0001F77F\U0001F780-\U0001F7FF\U0001F800-\U0001F8FF\U0001F900-\U0001F9FF\U0001FA00-\U0001FA6F\U0001FA70-\U0001FAFF]', content)
        if unicode_emojis:
            # ç®€å•å¤„ç†ï¼šæ¯ä¸ªUnicodeè¡¨æƒ…å¢åŠ 0.3åˆ†
            emoji_score += len(unicode_emojis) * 0.3

        # ä¸Šé™ä¸º2.0
        return min(abs(emoji_score), 2.0)

    def _predict_toxicity(self, text):
        """ä½¿ç”¨Detoxifyæ¨¡å‹é¢„æµ‹æ–‡æœ¬çš„æ¯’æ€§ï¼Œå¹¶ç»“åˆè‡ªå®šä¹‰è§„åˆ™å¤§å¹…å¢å¼ºæ£€æµ‹æ•ˆæœ"""
        if not self.detoxify_available or not text:
            return {"is_toxic": False, "toxicity_index": 0.0, "toxic_categories": [], "toxicity_score": 0.0}

        try:
            predictions = self.detoxify_model.predict(text)
            result = {
                "toxic": predictions.get("toxic", 0),
                "severe_toxic": predictions.get("severe_toxic", 0),
                "obscene": predictions.get("obscene", 0),
                "threat": predictions.get("threat", 0),
                "insult": predictions.get("insult", 0),
                "identity_hate": predictions.get("identity_hate", 0)
            }

            # --- è‡ªå®šä¹‰ç‰¹å¾è¯„åˆ† ---
            toxicity_score = 0.0
            detected_features = [] # ç”¨äºè®°å½•è§¦å‘çš„ç‰¹å¾ç±»å‹

            # åŒ¹é…æ‰€æœ‰æ¨¡å¼å¹¶ç´¯åŠ åˆ†æ•° (ç®€åŒ–åŒ¹é…é€»è¾‘)
            feature_scores = {
                "sarcasm_irony": 0.6,
                "death_related": 0.8,
                "business_criticism": 0.5,
                "emoji_combinations": 0.4, # å•ä¸ªè¡¨æƒ…ç»„åˆçš„åŸºç¡€åˆ†
                 # æ–°å¢ç±»åˆ«åŸºç¡€åˆ†
                "xiaomi_accident_attack": 0.7, # äº‹æ•…ç›¸å…³åŸºç¡€åˆ†é«˜
                "conspiracy_theory": 0.5,
                "competitor_attack": 0.4,
                "user_group_attack": 0.5,
                "generalization_attack": 0.4,
                "extreme_speech": 0.9 # æç«¯è¨€è®ºåŸºç¡€åˆ†é«˜
            }

            processed_text = self._preprocess_text(text)
            for category, patterns in self.all_patterns.items():
                if category not in feature_scores: continue # åªå¤„ç†æœ‰é¢„è®¾åˆ†æ•°çš„ç‰¹å¾ç±»åˆ«

                category_match_count = 0
                for pattern in patterns:
                    if pattern.search(processed_text):
                        category_match_count += 1
                        # å¯¹ç‰¹å®šé«˜å±æ¨¡å¼é¢å¤–åŠ åˆ†
                        if category == "xiaomi_accident_attack":
                            toxicity_score += 0.3 # æ¯æ¬¡åŒ¹é…äº‹æ•…æ”»å‡»éƒ½é¢å¤–åŠ åˆ†
                        elif category == "extreme_speech":
                             toxicity_score += 0.4
                        elif category == "death_related":
                             toxicity_score += 0.2

                if category_match_count > 0:
                    base_score = feature_scores.get(category, 0.3) # è·å–åŸºç¡€åˆ†ï¼Œé»˜è®¤ä¸º0.3
                    # æ ¹æ®åŒ¹é…æ¬¡æ•°è°ƒæ•´å¾—åˆ†ï¼Œå¢åŠ æƒé‡
                    category_score = base_score * (1 + (category_match_count - 1) * 0.8)
                    toxicity_score += category_score
                    detected_features.append(f"{category}(x{category_match_count})")

            # æ£€æŸ¥ç‰¹å®šè¡¨æƒ…ç»„åˆçš„ç‰¹æ®Šå¤„ç† (ä¾‹å¦‚å¤§é‡é‡å¤)
            variant_score, detected_variants, _ = self._check_variant_patterns(text)
            if variant_score > 0:
                toxicity_score += variant_score * 0.8 # å˜ä½“/ç¬¦å·å¾—åˆ†è´¡çŒ®æ˜¾è‘—æé«˜ (ä¿æŒ)
                detected_features.extend(detected_variants)


            # --- ä¿®æ­£Detoxifyé¢„æµ‹ç»“æœ ---
            # é™ä½è‡ªå®šä¹‰ç‰¹å¾è¯„åˆ†çš„å½±å“
            result["toxic"] = min(result["toxic"] + toxicity_score * 1.2, 1.0) # é™ä½å½±å“
            result["severe_toxic"] = min(result["severe_toxic"] + toxicity_score * 1.0, 1.0) # é™ä½å½±å“
            result["obscene"] = min(result["obscene"] + toxicity_score * 0.8, 1.0) # é™ä½å½±å“
            result["threat"] = min(result["threat"] + toxicity_score * 1.1, 1.0) # é™ä½å½±å“
            result["insult"] = min(result["insult"] + toxicity_score * 1.3, 1.0) # é™ä½å½±å“
            result["identity_hate"] = min(result["identity_hate"] + toxicity_score * 1.0, 1.0) # é™ä½å½±å“

            # --- åˆ¤æ–­æ˜¯å¦æœ‰æ¯’ ---
            is_toxic = False
            toxic_categories = []
            # ä½¿ç”¨æä½çš„é˜ˆå€¼ (ä¿æŒ)
            for category, score in result.items():
                 # è·³è¿‡éåˆ†æ•°çš„é”®
                if not isinstance(score, (int, float)): continue
                threshold = self.toxicity_thresholds.get(category, 0.15) # é»˜è®¤é˜ˆå€¼ä¹Ÿå¾ˆä½
                if score >= threshold:
                    is_toxic = True
                    toxic_categories.append(category)

            # è‡ªå®šä¹‰ç‰¹å¾åˆ†æ•°è¾¾åˆ°é˜ˆå€¼ä¹Ÿåˆ¤å®šä¸ºtoxic (é˜ˆå€¼ä¿æŒ)
            if toxicity_score >= 0.8: # ç‰¹å¾å¾—åˆ†è§¦å‘é˜ˆå€¼ (ä¿æŒ)
                is_toxic = True
                if "ç‰¹å¾åŒ¹é…" not in toxic_categories:
                    toxic_categories.append("ç‰¹å¾åŒ¹é…")

            # --- è®¡ç®—ç»¼åˆæ¯’æ€§æŒ‡æ•° ---
            # åŸºç¡€æ¯’æ€§å¾—åˆ† (åªå–ä¸¥é‡æ¯’æ€§ã€å¨èƒã€ä¾®è¾±)
            toxicity_base = sum(
                result.get(category, 0)
                for category in ["severe_toxic", "threat", "insult"]
            ) / 3

            # ç»¼åˆå¾—åˆ†è®¡ç®—: è°ƒæ•´è‡ªå®šä¹‰ç‰¹å¾è¯„åˆ†çš„æƒé‡
            toxicity_index = (
                toxicity_base * 0.20 +          # DetoxifyåŸºç¡€åˆ†æƒé‡æé«˜
                (toxicity_score * 0.80)         # è‡ªå®šä¹‰ç‰¹å¾åˆ†æƒé‡é™ä½
            )
            toxicity_index = min(toxicity_index, 1.0) # ä¸Šé™ä¸º1

            # --- æ•´ç†è¿”å›ç»“æœ ---
            final_result = {
                "is_toxic": is_toxic,
                "toxicity_index": toxicity_index,
                "toxic_categories": list(set(toxic_categories)), # å»é‡
                "toxicity_score": toxicity_score, # è‡ªå®šä¹‰ç‰¹å¾æ€»åˆ†
                "detected_features": detected_features, # è§¦å‘çš„ç‰¹å¾
                "detoxify_raw": {k: round(v, 4) for k, v in result.items() if isinstance(v, (int, float))} # ä¿ç•™åŸå§‹åˆ†æ•°ï¼ˆå››èˆäº”å…¥ï¼‰
            }
            return final_result

        except Exception as e:
            self.logger.error(f"Detoxifyæ¯’æ€§é¢„æµ‹å¤±è´¥: {e}")
            # è¿”å›ä¸€ä¸ªè¡¨ç¤ºå¤±è´¥ä½†ç»“æ„å®Œæ•´çš„å­—å…¸
            return {"is_toxic": False, "toxicity_index": 0.0, "toxic_categories": ["é¢„æµ‹å¤±è´¥"], "toxicity_score": 0.0}

    def enhanced_extreme_fan_detection(self, content):
        """
        å¢å¼ºç‰ˆåä¸ºæç«¯ç²‰ä¸æ£€æµ‹ï¼ˆæ ¸å¿ƒæ£€æµ‹é€»è¾‘ï¼‰
        æ•´åˆè§„åˆ™æ¨¡å¼åŒ¹é…ã€å¢å¼ºç‰ˆæƒ…æ„Ÿåˆ†æå’ŒåŸºäºDetoxifyçš„æ¯’æ€§åˆ†æï¼Œé‡‡ç”¨è°ƒæ•´åçš„åˆ¤å®šç­–ç•¥ã€‚
        """
        if not content or not isinstance(content, str) or len(content.strip()) < 3:
            return False, {"is_extreme": False, "reason": "å†…å®¹è¿‡çŸ­æˆ–æ ¼å¼ä¸æ­£ç¡®", "confidence": 0.0}

        result = {
            "is_extreme": False,
            "confidence": 0.0,
            "reasoning": [],
            "detection_methods": {"traditional_rule": False, "toxicity_analysis": False},
            "matched_patterns": {}, # è®°å½•åŒ¹é…åˆ°çš„è§„åˆ™æ¨¡å¼
            "toxicity_details": {} # è®°å½•æ¯’æ€§åˆ†æè¯¦æƒ…
        }

        # --- 1. ä¼ ç»Ÿè§„åˆ™æ¨¡å¼åŒ¹é… ---
        traditional_score = 0
        matched_patterns_details = {}
        processed_content = self._preprocess_text(content)
        has_xiaomi_mention = any(kw in processed_content for kw in self.xiaomi_special_terms)

        for category, patterns in self.all_patterns.items():
             # è·³è¿‡ä»…ç”¨äºæ¯’æ€§åˆ†æçš„ç±»åˆ«
            if category in ["sarcasm_irony", "death_related", "business_criticism", "emoji_combinations"]:
                continue

            category_match_count = 0
            matched_in_category = []
            for pattern in patterns:
                if pattern.search(processed_content):
                    category_match_count += 1
                    matched_in_category.append(pattern.pattern) # è®°å½•åŸå§‹æ­£åˆ™å­—ç¬¦ä¸²

            if category_match_count > 0:
                base_weight = self.feature_weights.get(category, 1.0)
                # æ ¹æ®åŒ¹é…æ¬¡æ•°å’Œæ˜¯å¦æåŠå°ç±³è°ƒæ•´åˆ†æ•°
                category_score = base_weight * (1 + (category_match_count - 1) * 0.5) # å¤šæ¬¡åŒ¹é…åŠ åˆ†
                if has_xiaomi_mention and category in ["xiaomi_accident_attack", "competitor_attack", "conspiracy_theory", "user_group_attack", "generalization_attack"]:
                    category_score *= 1.5 # æ¶‰åŠå°ç±³çš„è´Ÿé¢æ¨¡å¼æƒé‡æé«˜ (ä¿æŒ)
                traditional_score += category_score
                matched_patterns_details[category] = matched_in_category
                result["reasoning"].append(f"è§„åˆ™åŒ¹é…:{category}(x{category_match_count})")

        # å˜ä½“/ç¬¦å·å¾—åˆ†ä¹ŸåŠ å…¥ä¼ ç»Ÿè§„åˆ™è¯„åˆ†
        variant_score, detected_variants, _ = self._check_variant_patterns(content)
        if variant_score > 0:
            traditional_score += variant_score * 1.2 # å˜ä½“/ç¬¦å·å¾—åˆ†è´¡çŒ®æé«˜ (ä¿æŒ)
            result["reasoning"].append(f"æ£€æµ‹åˆ°å˜ä½“/ç‰¹æ®Šç¬¦å·(å¾—åˆ†è´¡çŒ®:{variant_score * 1.2:.2f})")
            if detected_variants:
                 # å°†å˜ä½“ä¿¡æ¯æ·»åŠ åˆ° matched_patterns
                matched_patterns_details["variant_symbols"] = detected_variants

        # --- 1.5 å¢å¼ºç‰ˆæƒ…æ„Ÿåˆ†æ ---
        sentiment_score = self.enhanced_sentiment_analysis(content)
        if sentiment_score > 3.0:  # æƒ…æ„Ÿå¼ºåº¦è¾ƒé«˜
            # æƒ…æ„Ÿå¼ºåº¦è´¡çŒ®åˆ°ä¼ ç»Ÿè§„åˆ™è¯„åˆ†
            sentiment_contribution = min((sentiment_score - 3.0) * 0.5, 2.0)  # æœ€å¤šè´¡çŒ®2.0åˆ†
            traditional_score += sentiment_contribution
            result["reasoning"].append(f"å¢å¼ºç‰ˆæƒ…æ„Ÿåˆ†æ: å¼ºåº¦={sentiment_score:.2f}, è´¡çŒ®={sentiment_contribution:.2f}")
            # å°†æƒ…æ„Ÿåˆ†æç»“æœæ·»åŠ åˆ°matched_patterns
            matched_patterns_details["high_sentiment"] = [f"æƒ…æ„Ÿå¼ºåº¦: {sentiment_score:.2f}"]

        is_traditional_extreme = traditional_score >= self.malicious_threshold_rule # ä½¿ç”¨è°ƒæ•´åçš„é˜ˆå€¼
        result["detection_methods"]["traditional_rule"] = is_traditional_extreme
        result["traditional_score"] = round(traditional_score, 2)
        result["matched_patterns"] = matched_patterns_details

        # --- 2. Detoxify æ¯’æ€§åˆ†æ ---
        toxicity_results = self._predict_toxicity(content)
        is_toxic = toxicity_results.get("is_toxic", False)
        toxicity_index = toxicity_results.get("toxicity_index", 0.0) # ä½¿ç”¨è°ƒæ•´åçš„è®¡ç®—æ–¹å¼
        toxicity_score_custom = toxicity_results.get("toxicity_score", 0.0) # è‡ªå®šä¹‰ç‰¹å¾åˆ†

        result["detection_methods"]["toxicity_analysis"] = is_toxic
        result["toxicity_details"] = toxicity_results # å­˜å‚¨å®Œæ•´æ¯’æ€§åˆ†æç»“æœ
        if is_toxic:
             result["reasoning"].append(f"æ¯’æ€§åˆ†æ: æŒ‡æ•°={toxicity_index:.2f}, è‡ªå®šä¹‰åˆ†={toxicity_score_custom:.2f}, ç±»åˆ«={','.join(toxicity_results.get('toxic_categories',[]))}")


        # --- 3. ç»“æœèåˆä¸æœ€ç»ˆåˆ¤å®š (è°ƒæ•´åç­–ç•¥) ---
        final_confidence = 0.0
        # åŸºç¡€ç½®ä¿¡åº¦ä¸»è¦æ¥è‡ªæ¯’æ€§åˆ†æ (è°ƒæ•´æƒé‡)
        if is_toxic:
            # æ¯’æ€§æŒ‡æ•°è´¡çŒ®é™ä½
            final_confidence += toxicity_index * 0.65 # é™ä½è´¡çŒ®
            # è‡ªå®šä¹‰ç‰¹å¾åˆ†è´¡çŒ®ç•¥å¾®é™ä½
            final_confidence += min(toxicity_score_custom / 5.0, 0.25) # è‡ªå®šä¹‰ç‰¹å¾åˆ†æœ€é«˜è´¡çŒ®é™ä½

        # ä¼ ç»Ÿè§„åˆ™å¾—åˆ†è´¡çŒ®ä¸€éƒ¨åˆ† (ä¿æŒ)
        if is_traditional_extreme:
             final_confidence += min(traditional_score / 8.0, 0.4) # è§„åˆ™å¾—åˆ†æœ€é«˜è´¡çŒ®ä¿æŒ

        # æ£€æµ‹æ–¹æ³•æ•°é‡åŠ æˆ (ä¿æŒ)
        detection_count = sum(result["detection_methods"].values())
        if detection_count >= 2:
            final_confidence += 0.3 # ä¸¤ç§æ–¹æ³•éƒ½å‘½ä¸­åˆ™åŠ 0.3ç½®ä¿¡åº¦

        final_confidence = min(final_confidence, 0.99) # æœ€é«˜ç½®ä¿¡åº¦0.99
        result["confidence"] = round(final_confidence, 2)

        # æœ€ç»ˆåˆ¤å®š (è°ƒæ•´å•ä¸€æ–¹æ³•é˜ˆå€¼å’Œä¸¥é‡æ¯’æ€§/å¨èƒçš„è§¦å‘æ¡ä»¶)
        reasons_for_extreme = []
        if detection_count >= 2:
             reasons_for_extreme.append("è§„åˆ™å’Œæ¯’æ€§åˆ†æå‡å‘½ä¸­")
        if detection_count == 1 and final_confidence >= self.confidence_threshold_final: # ä½¿ç”¨è°ƒæ•´åçš„é˜ˆå€¼
             reasons_for_extreme.append(f"å•ä¸€æ–¹æ³•å‘½ä¸­ä¸”ç½®ä¿¡åº¦({final_confidence:.2f})è¾¾æ ‡")
        # å¢åŠ å¯¹ä¸¥é‡æ¯’æ€§/å¨èƒè§¦å‘çš„é¢å¤–è¦æ±‚
        if is_toxic and ("severe_toxic" in toxicity_results.get("toxic_categories", []) or "threat" in toxicity_results.get("toxic_categories", [])) and toxicity_index >= 0.5:
             reasons_for_extreme.append("æ£€æµ‹åˆ°ä¸¥é‡æ¯’æ€§æˆ–å¨èƒ(ä¸”ç»¼åˆæŒ‡æ•°>=0.5)")
        if is_traditional_extreme and "xiaomi_accident_attack" in matched_patterns_details and traditional_score >= self.high_risk_score_threshold:
             reasons_for_extreme.append(f"é«˜å±æ¨¡å¼(å°ç±³è½¦ç¥¸æ”»å‡»)ä¸”è§„åˆ™å¾—åˆ†({traditional_score:.2f})è¾¾æ ‡")
        if toxicity_score_custom >= self.high_toxicity_score_threshold: # ä½¿ç”¨è°ƒæ•´åçš„è‡ªå®šä¹‰ç‰¹å¾åˆ†ç›´æ¥è§¦å‘é˜ˆå€¼
             reasons_for_extreme.append(f"è‡ªå®šä¹‰ç‰¹å¾åˆ†æ•°({toxicity_score_custom:.2f})è¿‡é«˜")

        result["is_extreme"] = len(reasons_for_extreme) > 0
        if result["is_extreme"]:
            result["final_judgement_reason"] = " | ".join(reasons_for_extreme)
            # è®°å½•æç«¯ç±»å‹ï¼ˆå¯é€‰ï¼Œå¯ä»¥åŸºäºåŒ¹é…çš„æ¨¡å¼æˆ–æ¯’æ€§ç±»åˆ«åˆ¤æ–­ï¼‰
            result["extreme_types"] = self._determine_extreme_types_from_result(result)

        # å®Œå–„æ¨ç†è¯´æ˜
        if result["reasoning"]:
            result["reasoning_summary"] = " | ".join(result["reasoning"])

        return result["is_extreme"], result

    def _determine_extreme_types_from_result(self, result):
        """æ ¹æ®æ£€æµ‹ç»“æœæ¨æ–­æç«¯ç±»å‹"""
        types = set()
        if result.get("matched_patterns"):
            patterns = result["matched_patterns"]
            if "blind_worship" in patterns: types.add("å“ç‰Œå´‡æ‹œ")
            if "conspiracy_theory" in patterns: types.add("é˜´è°‹è®º")
            if "competitor_attack" in patterns: types.add("ç«å“æ”»å‡»")
            if "user_group_attack" in patterns: types.add("ç”¨æˆ·ç¾¤ä½“æ”»å‡»")
            if "generalization_attack" in patterns: types.add("æ³›åŒ–æ”»å‡»")
            if "nationalism" in patterns: types.add("æ°‘æ—ä¸»ä¹‰")
            if "tech_exaggeration" in patterns: types.add("æŠ€æœ¯å¤¸å¤§")
            if "extreme_speech" in patterns: types.add("æç«¯è¨€è®º/è¯…å’’")
            if "xiaomi_accident_attack" in patterns: types.add("å¹¸ç¾ä¹ç¥¸/äº‹æ•…æ”»å‡»")
        if result.get("toxicity_details"):
            toxicity = result["toxicity_details"]
            if toxicity.get("is_toxic"):
                if "ç‰¹å¾åŒ¹é…" in toxicity.get("toxic_categories",[]): types.add("è®½åˆº/é˜´é˜³æ€ªæ°”")
                if "severe_toxic" in toxicity.get("toxic_categories",[]): types.add("ä¸¥é‡æ¯’æ€§")
                if "threat" in toxicity.get("toxic_categories",[]): types.add("å¨èƒ")
                if "insult" in toxicity.get("toxic_categories",[]): types.add("ä¾®è¾±")
                if "identity_hate" in toxicity.get("toxic_categories",[]): types.add("èº«ä»½ä»‡æ¨")
        return list(types)

    # --- ä¿ç•™æ ¸å¿ƒæ£€æµ‹æ¥å£ detect_huawei_fanatic ---
    def detect_huawei_fanatic(self, content, comment_id=None, user_id=None):
        """
        ç»¼åˆæ£€æµ‹åä¸ºæç«¯ç²‰ä¸è¨€è®ºå’Œå°ç±³æ”»å‡»è¨€è®º (ä¸»è¦æ£€æµ‹æ¥å£)
        ç°åœ¨ç›´æ¥è°ƒç”¨å¢å¼ºç‰ˆæ£€æµ‹é€»è¾‘ã€‚
        """
        self.detection_count += 1
        log_prefix = f"[è¯„è®ºID:{comment_id or 'æœªçŸ¥'}|ç”¨æˆ·ID:{user_id or 'æœªçŸ¥'}]"
        self.logger.info(f"{log_prefix} å¼€å§‹æ£€æµ‹ #{self.detection_count} - å†…å®¹é•¿åº¦: {len(content) if content else 0}")
        if content and len(content) <= 100:
            self.logger.info(f"{log_prefix} åŸå§‹å†…å®¹: {content}")
        elif content:
            self.logger.info(f"{log_prefix} åŸå§‹å†…å®¹è¿‡é•¿, å¼€å¤´100å­—ç¬¦: {content[:100]}...")

        is_extreme, detection_result = self.enhanced_extreme_fan_detection(content)

        # æ„å»ºä¸ä¹‹å‰å…¼å®¹çš„è¾“å‡ºç»“æ„ï¼Œä½†åŒ…å«æ›´ä¸°å¯Œçš„ç»†èŠ‚
        result = {
            "is_huawei_fanatic": is_extreme, # ä¿æŒå­—æ®µåå…¼å®¹
            "confidence": detection_result.get("confidence", 0),
            "detection_summary": {}
        }

        if is_extreme:
            self.extreme_count += 1
            self.logger.warning(f"{log_prefix} #{self.detection_count} - æ£€æµ‹åˆ°æç«¯è¨€è®º! ç½®ä¿¡åº¦: {result['confidence']:.2f}")
            self.logger.warning(f"{log_prefix} åˆ¤å®šç†ç”±: {detection_result.get('final_judgement_reason', 'N/A')}")

            result["detection_summary"] = {
                "detection_methods": detection_result.get("detection_methods", {}),
                "reasoning": detection_result.get("reasoning_summary", ""),
                "extreme_types": detection_result.get("extreme_types", []),
                "rule_score": detection_result.get("traditional_score", 0),
                "matched_patterns": detection_result.get("matched_patterns", {}),
                "toxicity_details": detection_result.get("toxicity_details", {})
            }
            # è®°å½•æ›´è¯¦ç»†çš„æ—¥å¿—
            if result["detection_summary"].get("extreme_types"):
                 self.logger.warning(f"{log_prefix} æç«¯ç±»å‹: {', '.join(result['detection_summary']['extreme_types'])}")
            if result["detection_summary"].get("matched_patterns"):
                pattern_summary = "; ".join([f"{k}({len(v)})" for k, v in result["detection_summary"]["matched_patterns"].items()])
                self.logger.warning(f"{log_prefix} åŒ¹é…æ¨¡å¼: {pattern_summary}")
            if result["detection_summary"].get("toxicity_details", {}).get("is_toxic"):
                tox_details = result["detection_summary"]["toxicity_details"]
                self.logger.warning(f"{log_prefix} æ¯’æ€§åˆ†æ: æŒ‡æ•°={tox_details.get('toxicity_index',0):.2f}, è‡ªå®šä¹‰åˆ†={tox_details.get('toxicity_score',0):.2f}, ç±»åˆ«={','.join(tox_details.get('toxic_categories',[]))}")

        else:
            self.logger.info(f"{log_prefix} #{self.detection_count} - æœªæ£€æµ‹åˆ°æç«¯è¨€è®º. ç½®ä¿¡åº¦: {result['confidence']:.2f}")
            if result['confidence'] > 0.4: # è®°å½•ç½®ä¿¡åº¦è¾ƒé«˜ä½†æœªè¾¾æ ‡çš„æƒ…å†µ
                 self.logger.info(f"{log_prefix} æ³¨æ„: ç½®ä¿¡åº¦è¾ƒé«˜ä½†æœªè¾¾æ ‡. æ¨ç†: {detection_result.get('reasoning_summary', 'N/A')}")


        if self.detection_count > 0 and self.detection_count % 100 == 0:
            detection_rate = (self.extreme_count / self.detection_count) * 100
            self.logger.info(f"ç´¯è®¡ç»Ÿè®¡: å·²æ£€æµ‹ {self.detection_count} æ¡è¯„è®º, å‘ç° {self.extreme_count} æ¡æç«¯è¨€è®º (æ¯”ç‡: {detection_rate:.2f}%)")

        return result

    # --- ç§»é™¤æˆ–æ³¨é‡Šæ‰ä¸å†éœ€è¦/å†—ä½™çš„æ–¹æ³• ---
    # def detect_fanatic_comment(self, content): ... (é€»è¾‘å·²æ•´åˆ)
    # def determine_extreme_types(self, content): ... (é€»è¾‘å·²æ•´åˆ)
    # def llm_based_fanaticism_detection(self, content): ... (é€»è¾‘å·²æ•´åˆ)
    # def _is_huawei_fanatic_comment(self, content): ... (é€»è¾‘å·²æ•´åˆ)
    # def detect_xiaomi_car_extremism(self, content): ... (æ¨¡å¼å·²æ•´åˆ)

    def analyze_comment_context(self, comment, video_title, other_comments=None):
        """
        åˆ†æè¯„è®ºçš„ä¸Šä¸‹æ–‡ï¼Œè€ƒè™‘è§†é¢‘æ ‡é¢˜å’Œå…¶ä»–è¯„è®º

        Args:
            comment: è¯„è®ºå†…å®¹
            video_title: è§†é¢‘æ ‡é¢˜
            other_comments: åŒä¸€è§†é¢‘ä¸‹çš„å…¶ä»–è¯„è®º

        Returns:
            context_score: ä¸Šä¸‹æ–‡ç›¸å…³æ€§å¾—åˆ†
            context_info: ä¸Šä¸‹æ–‡åˆ†æä¿¡æ¯
        """
        if not comment or not video_title:
            return 0, {}

        context_score = 0
        context_info = {}

        # 1. æ£€æŸ¥è¯„è®ºä¸è§†é¢‘æ ‡é¢˜çš„ç›¸å…³æ€§
        # å¦‚æœè§†é¢‘æ ‡é¢˜åŒ…å«åä¸ºç›¸å…³å…³é”®è¯ï¼Œå¢åŠ æƒé‡
        huawei_related = False
        xiaomi_related = False

        # æ£€æŸ¥è§†é¢‘æ ‡é¢˜æ˜¯å¦ä¸åä¸ºç›¸å…³
        if any(kw in video_title.lower() for kw in self.huawei_special_terms):
            huawei_related = True
            context_score += 0.5
            context_info["video_huawei_related"] = True

        # æ£€æŸ¥è§†é¢‘æ ‡é¢˜æ˜¯å¦ä¸å°ç±³ç›¸å…³
        if any(kw in video_title.lower() for kw in self.xiaomi_special_terms):
            xiaomi_related = True
            context_score += 0.5
            context_info["video_xiaomi_related"] = True

        # 2. æ£€æŸ¥æ˜¯å¦æ˜¯å›å¤å…¶ä»–è¯„è®º
        is_reply = False
        if isinstance(comment, dict) and comment.get("parent", 0) > 0:
            is_reply = True
            context_score += 0.3
            context_info["is_reply"] = True

        # 3. åˆ†æè¯„è®ºå†…å®¹ä¸è§†é¢‘ä¸»é¢˜çš„ç›¸å…³æ€§
        content = ""
        if isinstance(comment, dict) and "content" in comment:
            if isinstance(comment["content"], dict) and "message" in comment["content"]:
                content = comment["content"]["message"]
            elif isinstance(comment["content"], str):
                content = comment["content"]
        elif isinstance(comment, str):
            content = comment

        # å¦‚æœè¯„è®ºå†…å®¹ä¸è§†é¢‘ä¸»é¢˜ç›¸å…³ï¼Œå¢åŠ æƒé‡
        if huawei_related and any(kw in content.lower() for kw in self.huawei_special_terms):
            context_score += 0.4
            context_info["comment_huawei_related"] = True

        if xiaomi_related and any(kw in content.lower() for kw in self.xiaomi_special_terms):
            context_score += 0.4
            context_info["comment_xiaomi_related"] = True

        # 4. åˆ†æè¯„è®ºæƒ…æ„Ÿä¸è§†é¢‘ä¸»é¢˜çš„ä¸€è‡´æ€§
        # å¦‚æœè§†é¢‘æ˜¯å…³äºåä¸ºçš„ï¼Œè€Œè¯„è®ºå¯¹åä¸ºæŒè´Ÿé¢æ€åº¦ï¼Œå¯èƒ½æ˜¯ç«å“ç²‰ä¸
        # å¦‚æœè§†é¢‘æ˜¯å…³äºå°ç±³çš„ï¼Œè€Œè¯„è®ºå¯¹å°ç±³æŒè´Ÿé¢æ€åº¦ï¼Œå¯èƒ½æ˜¯åä¸ºæç«¯ç²‰ä¸
        if huawei_related:
            sentiment_score = self._analyze_emotional_intensity(content)
            if sentiment_score > 3:  # æƒ…æ„Ÿå¼ºåº¦è¾ƒé«˜
                context_score += 0.3
                context_info["high_emotion_huawei_video"] = True

        if xiaomi_related:
            sentiment_score = self._analyze_emotional_intensity(content)
            if sentiment_score > 3:  # æƒ…æ„Ÿå¼ºåº¦è¾ƒé«˜
                context_score += 0.3
                context_info["high_emotion_xiaomi_video"] = True

        # 5. åˆ†æå…¶ä»–è¯„è®ºçš„æƒ…å†µï¼ˆå¦‚æœæä¾›ï¼‰
        if other_comments and len(other_comments) > 0:
            # è®¡ç®—åŒä¸€è§†é¢‘ä¸‹æç«¯è¯„è®ºçš„æ¯”ä¾‹
            extreme_count = 0
            for other_comment in other_comments[:20]:  # åªåˆ†æå‰20æ¡è¯„è®º
                other_content = ""
                if isinstance(other_comment, dict):
                    if isinstance(other_comment.get("content"), dict):
                        other_content = other_comment["content"].get("message", "")
                    elif isinstance(other_comment.get("content"), str):
                        other_content = other_comment["content"]

                if other_content:
                    # ç®€å•æ£€æŸ¥æ˜¯å¦å¯èƒ½æ˜¯æç«¯è¯„è®º
                    is_extreme, _ = self.enhanced_extreme_fan_detection(other_content)
                    if is_extreme:
                        extreme_count += 1

            # å¦‚æœåŒä¸€è§†é¢‘ä¸‹æç«¯è¯„è®ºæ¯”ä¾‹è¾ƒé«˜ï¼Œå¢åŠ æƒé‡
            extreme_ratio = extreme_count / min(len(other_comments), 20)
            if extreme_ratio > 0.3:  # è¶…è¿‡30%çš„è¯„è®ºæ˜¯æç«¯è¯„è®º
                context_score += 0.4
                context_info["high_extreme_ratio"] = extreme_ratio

        return context_score, context_info

    def record_false_positive(self, content, detection_result):
        """è®°å½•è¯¯åˆ¤æ ·æœ¬"""
        try:
            # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
            log_dir = "logs"
            if not os.path.exists(log_dir):
                os.makedirs(log_dir)

            # è®°å½•åˆ°æ–‡ä»¶
            false_positives_file = os.path.join(log_dir, "false_positives.jsonl")
            with open(false_positives_file, "a", encoding="utf-8") as f:
                record = {
                    "content": content,
                    "detection_result": detection_result,
                    "timestamp": datetime.now().isoformat()
                }
                f.write(json.dumps(record, ensure_ascii=False) + "\n")

            print(f"å·²è®°å½•è¯¯åˆ¤æ ·æœ¬åˆ° {false_positives_file}")
            return True
        except Exception as e:
            print(f"è®°å½•è¯¯åˆ¤æ ·æœ¬å¤±è´¥: {e}")
            return False

    def record_false_negative(self, content, comment_info=None):
        """è®°å½•æ¼åˆ¤æ ·æœ¬"""
        try:
            # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
            log_dir = "logs"
            if not os.path.exists(log_dir):
                os.makedirs(log_dir)

            # è®°å½•åˆ°æ–‡ä»¶
            false_negatives_file = os.path.join(log_dir, "false_negatives.jsonl")
            with open(false_negatives_file, "a", encoding="utf-8") as f:
                record = {
                    "content": content,
                    "comment_info": comment_info or {},
                    "timestamp": datetime.now().isoformat()
                }
                f.write(json.dumps(record, ensure_ascii=False) + "\n")

            print(f"å·²è®°å½•æ¼åˆ¤æ ·æœ¬åˆ° {false_negatives_file}")
            return True
        except Exception as e:
            print(f"è®°å½•æ¼åˆ¤æ ·æœ¬å¤±è´¥: {e}")
            return False

    def calculate_report_priority(self, comment, detection_result):
        """è®¡ç®—ä¸¾æŠ¥ä¼˜å…ˆçº§"""
        # åŸºç¡€åˆ†æ•° - ç½®ä¿¡åº¦
        base_score = detection_result.get("confidence", 0) * 10  # 0-10åˆ†

        # è¯„è®ºç‚¹èµæ•°å› ç´  - é«˜ç‚¹èµçš„æœ‰å®³è¯„è®ºå½±å“æ›´å¤§
        like_count = comment.get("like", 0)
        like_score = min(like_count / 50, 5)  # æœ€é«˜5åˆ†

        # è¯„è®ºæ–°é²œåº¦ - ä¼˜å…ˆå¤„ç†è¾ƒæ–°çš„è¯„è®º
        ctime = comment.get("ctime", time.time())
        age_in_days = (time.time() - ctime) / (24 * 3600)
        freshness_score = max(5 - age_in_days, 0) if age_in_days <= 5 else 0  # æœ€é«˜5åˆ†

        # ç”¨æˆ·ç­‰çº§å› ç´  - é«˜ç­‰çº§ç”¨æˆ·çš„æœ‰å®³è¯„è®ºå½±å“æ›´å¤§
        user_level = comment.get("member", {}).get("level_info", {}).get("current_level", 0)
        level_score = min(user_level, 6) * 0.5  # æœ€é«˜3åˆ†

        # æç«¯ç±»å‹å› ç´  - æŸäº›æç«¯ç±»å‹ä¼˜å…ˆå¤„ç†
        extreme_types = detection_result.get("detection_summary", {}).get("extreme_types", [])
        type_score = 0
        priority_types = ["æç«¯è¨€è®º/è¯…å’’", "å¹¸ç¾ä¹ç¥¸/äº‹æ•…æ”»å‡»", "äººèº«æ”»å‡»"]
        for t in extreme_types:
            if t in priority_types:
                type_score += 2
        type_score = min(type_score, 6)  # æœ€é«˜6åˆ†

        # ä¸Šä¸‹æ–‡å› ç´  - å¦‚æœè¯„è®ºåŒºå·²ç»æœ‰å¤šæ¡ç±»ä¼¼è¯„è®ºï¼Œä¼˜å…ˆå¤„ç†
        context_info = detection_result.get("detection_summary", {}).get("context_info", {})
        context_score = 0
        if context_info.get("toxic_atmosphere", 0) > 0.3:
            context_score += 3  # è¯„è®ºåŒºæ°›å›´å·²æ¶åŒ–ï¼Œä¼˜å…ˆå¤„ç†
        if context_info.get("high_extreme_ratio", 0) > 0.3:
            context_score += 2  # æç«¯è¯„è®ºæ¯”ä¾‹é«˜ï¼Œä¼˜å…ˆå¤„ç†

        # è®¡ç®—æ€»åˆ†
        total_score = base_score + like_score + freshness_score + level_score + type_score + context_score

        return total_score

# --- æµ‹è¯•å‡½æ•°æ›´æ–° ---
def test_xiaomi_car_comments():
    """æµ‹è¯•å°ç±³è½¦ç¥¸ç›¸å…³è¯„è®ºè¯†åˆ«"""
    detector = HuaweiFanaticDetector()
    test_comments = [
        "å‘å¸ƒçš„æ—¶å€™ ä»€ä¹ˆéƒ½æ˜¯è‡ªç ”çš„ æ¯”è°è°éƒ½å¼º æœ‰ç‚¹åŠ¨é™å°±æ˜¯åˆ«äººçš„äº†[åƒç“œ][æ‚çœ¼]æŒºå¥½ åå™¬ç»ˆä¼šåˆ°æ¥ ğŸµåˆ«æ¥æˆ‘è¿™è¯„è®º[æ»‘ç¨½]åœ¨æˆ‘è¿™è¯„è®ºçš„ğŸµ è¯…å’’ä½ ä¸€å®¶éƒ½ä¼šå»çš„å¾ˆæ‚²æƒ¨[æ»‘ç¨½]",
        "ä»»ä½•ä»·æ ¼çš„è½¦éƒ½ä¸èƒ½æ˜¯ä¸€ä¸ªç§»åŠ¨æ£ºæå¯¹å§",
        "å¤§æ¦‚ç‡å°±æ˜¯æŠ€æœ¯å¤ªèœåˆèœœæ±è‡ªä¿¡",
        "æ²¡æœ‰å¦‚æœ å•¥è°æˆæ€§",
        "ä½é…è¿˜æ•¢å¼€æ™ºé©¾ï¼Œè¿˜æ˜¯å°ç±³çš„ã€‚ã€‚ã€‚",
        "çœŸå¯æ€•ï¼Œæ­»äº†äººï¼Œè¿˜ğŸˆ¶äººå¸®è½¦ä¼è¯´è¯",
        "è¿™su7å°±æ˜¯ä¸ä¸€æ ·å•Šï¼Œå†’å‡ºè¿™ä¹ˆç†ä¸­å®¢æ¥è®¨è®ºï¼Œæ€ä¹ˆå‡ºäº‹é‚£å¤©æ¢éš”å£é‚£è½¦ä¸å¾—çŸ­ä¿¡å¾®åšè®©å…¨ä¸–ç•Œéƒ½çŸ¥é“å•Šï¼Œè¿™ç±³å…¬å…³å‹ä¸ä½äº†ï¼Œæ‰å‡ºæ¥[åƒç“œ]ï¼Œé›·å¤§å–„äººçš„æŠŠä½ ä»¬çš„å‘½ä¹Ÿå½“æ€§ä»·æ¯”",
        "å°ç±³æ‰‹æœºæˆ‘éƒ½ä¸ç”¨ã€‚",
        "æˆ‘å°±è¯´ï¼Œé€ æ‰‹æœºçš„é€ æ±½è½¦ï¼Œä»–ä¸æˆäº‹ä»–ä¸ä¸­ç”¨ï¼Œæ‰€ä»¥è¯´ä¹°äº†å° ç±³è½¦çš„è¦å°å¿ƒåªèƒ½æ¨è‡ªå·±ï¼Œä¸è¡Œå’±æŠ•é™è¾“ä¸€åŠï¼Œå«å°ç±³å›æ”¶å§",
        "å“å‘€ï¼Œä¸ä¿¡ä»»æ–°èƒ½æºä½ å°±ä¸ä¹°å˜›ï¼Œä¿¡ä»»æ–°èƒ½æºå°±ä¹°å˜›ï¼Œè¿™ç¾¤äºº åœ¨ç½‘ä¸Šå–·ä»€ä¹ˆ",
        "è¿™å›æ˜¯æŠŠè‚¡å¸‚ä»·æ ¼æ‰“ä¸‹æ¥äº†ï¼Œé›·æ€»çš„æ©æƒ…è¿™å›ä¹Ÿè¿˜å®Œäº†ï¼Œå°±æ˜¯æ„Ÿåˆ°å¯æƒœï¼Œä½ è¯´ä½ 110å¤šçš„é€Ÿåº¦å§ï¼Œåœ¨é«˜é€Ÿä¸Šç¡®å®ä¸ç®—å¤šå¿«ã€‚å¯è§ä½ ä¹Ÿæ²¡æŠŠé€Ÿåº¦å½“æ˜¯ä¿¡ä»°ï¼Œé—®é¢˜æ˜¯è¯´ä½ ä¸ä¿¡åå­çš„æ™ºèƒ½é©¾é©¶ï¼Œæˆ‘å¾ˆç†è§£ã€‚ä½†æ˜¯ä½ ä¿¡å°ç±³ çš„æ™ºé©¾è¿˜æ•¢åœ¨...",
        "ç±³å®¶æ´—ç™½çš„è¿˜æ˜¯å¤šå•Šï¼Œä¸Šæ¬¡é—®ç•Œæ€ä¹ˆæ²¡è¿™ä¹ˆå¤šç†ä¸­å®¢",
        "æ¶è‡­å…¬å¸çš„å›æ—‹é•–è™½è¿Ÿä½†åˆ°ï¼ŒçŒ•çŒ´ä»¬çš„ç¦æŠ¥æ¥å•¦",
        "è®ºçœŸæç¬‘ï¼Œå‡ºäº‹çš„æ˜¯å°ç±³ï¼Œå´éƒ½åœ¨å¾€åä¸ºæ™ºé©¾ä¸Šå¸¦ï¼Œä½ ä»¬çš„ æ„æ€æ˜¯è¿™è½¦æ­è½½çš„åä¸ºçš„æ™ºé©¾ç³»ç»Ÿï¼Ÿ",
        "ä¹°äº†çš„èµ¶ç´§å–å§ ä¸ç„¶ä»¥åå°±æ˜¯åºŸé“ä»·",
        # æ–°å¢æµ‹è¯•ç”¨ä¾‹
        "å°ç±³æ˜é¢ä¸Šè‡´æ•¬ç‰¹æ–¯æ‹‰ä¿æ—¶æ·ï¼Œä½†æ˜¯åœ¨è¥é”€ä¸Šï¼Œåˆ«äººæ±½è½¦å‘å¸ƒ ï¼Œæ­£å¸¸å®£ä¼ ï¼Œéƒ½è¢«è¹­å®Œäº†è¿˜è¦æ‹¿å‡ºæ¥å’Œé›·å†›ç›¸æ¯”ï¼Œå¯¹æ¯”æ‹‰è¸©ä¸€ç•ªï¼Œæœ¬èº«æ–°è½¦å‘å¸ƒå°±æƒ³çœ‹ä¸€ä¸‹æœ‰å…³äºè¿™æ¬¾è½¦çš„è§†é¢‘ï¼Œå…¨æ˜¯ä¸€äº›å¤¸å°ç±³é›·å†›çš„ã€‚",
        "ä¸æ•¢è¯´è¯å’¯ï¼Œåˆ°åº•è°å®¶æ‚å˜´æ‚å¾—æœ€ç‹ å•Š[å¤§ç¬‘][å¤§ç¬‘][å¤§ç¬‘]",
        "upå¤ªå¤šç»“æœæ¨å¯¼ æˆ‘ä¸çœ‹å¥½å°ç±³æ±½è½¦ ä½†æ˜¯çœŸå¿ƒå¸Œæœ›å°ç±³æ±½è½¦èƒ½ å¤ŸæˆåŠŸ å°ç±³æœ€å¤§çš„é—®é¢˜å°±æ˜¯ç±³ç²‰ å¤ªå¤šäººä¸äº†è§£ç”µè½¦ ä¹°å°ç±³æ±½è½¦æ˜¯å› ä¸ºå°ç±³å’Œé›·å†›",
        "å°ç±³æ˜¯ä¸æ‰é˜Ÿï¼Œä¹Ÿä¸ä¸»æ¨ï¼Œé‚£æ˜¯å› ä¸ºä¸æ„¿æ„æ›´å¤šæŠ•å…¥ç ”å‘ï¼Œæ‹¿ ä»€ä¹ˆå»ä¸»æ¨å‘¢ã€‚ä»è¿™ä¸ªäº‹æ•…æˆ‘çœ‹å‡ºæ¥äº†ï¼Œå°ç±³æ±½è½¦è¿˜æ˜¯çœŸèƒ½æˆåŠŸï¼Œç±³ç²‰çœŸçš„ä¿¡ä»°å·²ç»è¾¾åˆ°å¦‚ç—´å¦‚é†‰çš„é¡¶å³°é˜¶æ®µäº†ã€‚",
        "å¾—ä¸å€Ÿç”¨å¼¹å¹•çš„ä¸€å¥è¯ï¼Œå®¢è§‚åˆ†æçš„å¤©èŠ±æ¿ï¼Œä»¥å‰æˆ‘æ˜¯ç±³ç²‰ ï¼Œç°åœ¨ç»å¯¹ç®—ä¸ä¸Šäº†ï¼Œï¼Œè‡³äºè¯´ä¸ºå•¥ä¸æ˜¯ç±³ç²‰äº†ï¼Œè¿™å‡ å¹´æ‰‹æœºç”¨ä¸‹æ¥çœŸçš„å¾ˆéš¾ä¸è„±ç²‰",
        "å…¶å®æœ‰ä¸€éƒ¨åˆ†äººç¾¤çš„ç–‘é—®å°±æ˜¯ï¼Œå»å¹´å±±è¥¿é‚£æ¬¡è½¦ç¥¸æ˜¯æ–°ä¸­å›½ç¬¬ ä¸€æ¬¡è½¦ç¥¸å—ï¼Ÿä¸ºä»€ä¹ˆè¿™æ¬¡çš„ç½‘å‹éƒ½é‚£ä¹ˆé‚£ä¹ˆå…‹åˆ¶ï¼Œé‚£ä¹ˆä¸ºä»€ä¹ˆåœ¨å±±è¥¿é‚£æ¬¡çƒ­æœé‚£ä¹ˆå¤šï¼Œä¸ºä»€ä¹ˆè¿™æ¬¡è½¦ç¥¸ä¸‰å¤©åæ‰å¼€å§‹æœ‰èŠ‚å¥",
        "å°ç±³å…¬å¸çš„é‡å¿ƒå…¨éƒ½åå‘è½¦äº†ï¼Œæ„Ÿè§‰15uå°±æ˜¯ä¸ªè¾¹ç¼˜éƒ¨é—¨éšä¾¿å¼„çš„",
        "è‡ªå·±åƒå›æ—‹é•–å°±è¯´æ˜¯è¢«å¸¦èŠ‚å¥äº†[ç¬‘å“­]åŒ—äº¬æ‚å˜´ç‹",
        "å°ç±³å°±æ˜¯ä¸€è´´ç‰Œå…¬å¸ï¼Œä»€ä¹ˆéƒ½æ’ä¸€è„šï¼Œç©ºè°ƒï¼Œçƒ­æ°´å™¨ï¼Œç”µè§†ï¼Œç”µè„‘ï¼Œæ±½è½¦ã€‚ä½ è¯´ä»–å¸¦åŠ¨ä¸‹æ¸¸äº§ä¸šï¼Œæ–°èƒ½æºå¸‚åœºå°ç±³ä¸æ˜¯å…ˆé©±è€…ï¼Œä»–æ›´åƒæ›¾ç»çš„è…¾è®¯ï¼Œä½ å…ˆåšï¼Œå¸‚åœºæˆç†Ÿäº†æˆ‘å°±ä¸‹åœºæ”¶å‰²ã€‚è¿™æ ·çš„ç¯å¢ƒçœŸçš„å¥½å—ï¼Ÿä½ è¿™æ˜¯å“ç‰Œéœ¸æƒã€‚",
        "ä½†æ˜¯æˆ‘çœ‹æ–°é—»ï¼Œå¥½åƒæ¯ä¸€æ¬¡å°ç±³æ±½è½¦å‡ºé—®é¢˜çš„è²Œä¼¼éƒ½æ˜¯æ“ä½œäºº çš„é—®é¢˜ï¼Œæ±½è½¦è‡ªå·±æœ¬èº«çš„é—®é¢˜å¥½åƒåªæœ‰ä¸€æ¬¡otaå›ºä»¶æ¨é€é”™äº†æ˜¯å®ƒè‡ªå·±æœ¬èº«çš„é—®é¢˜ï¼Œè¿˜çœŸæ²¡çœ‹åˆ°æ±½è½¦è‡ªèº«é—®é¢˜çš„ã€‚[ç¬‘å“­]",
        "åˆ°ç°åœ¨è¿˜æœ‰ç»™å°ç±³ç»„è£…å‚ é è¥é”€ é›·ä¸ç¾¤ ä¹°åŠçš„æ ‡ç­¾ï¼Œä¸€ç›´åœ¨é€†é£å±€",
        "æœˆä»½åˆšå‘å”®ï¼šå—¨å°±æ˜¯ä¸€ç»„è£…è½¦ï¼Œæ²¡å•¥æŠ€æœ¯å¡æ²¡çœ‹äººå®¶bydåä¸º\n2ã€6æœˆä»½ï¼šè½¦é•¿çš„ä¸é”™ï¼Œæœ‰ç‚¹å°å¸…\n3ã€7æœˆä»½:æˆ‘è®¡åˆ’ä¹°æ±‰ï¼Œåˆæ²¡å•¥ä¹°ç‚¹\n4ã€8æœˆä»½ä¸€å¥³æ€§æœ‹å‹ä¸€ç›´è¯´å–œæ¬¢ï¼Œæˆ‘å°±å¤šäº†è§£äº†ä¸€ä¸‹ï¼Œçœ‹äº†å¥½å¤šè½¦ç¥¸è§†é¢‘ã€‚å†³å®šä»¥åå°±ä¹°ä»–äº†\n5ã€9æœˆä»½å»é™„è¿‘åº—è¯•é©¾ï¼Œå¼€èµ·å¼€ä¸å­¬\n6ã€ç‰›é€¼è¿™è½¦ï¼Œæ¯ä¸€æ¬¡äº‹æ•…èƒ½çœ‹çš„æˆ‘éƒ½çœ‹ï¼Œçœ‹çœ‹ç©¶ç«Ÿæ˜¯è½¦çš„é—®é¢˜è¿˜æ˜¯å¼€è½¦çš„é—®é¢˜ã€‚ä½†æ˜¯æ²¡æœ‰ä¸€æ¬¡ä¾‹å¤–ï¼Œè½¦æ²¡é—®é¢˜ã€‚",
        "å’‹éƒ½ä¸è®¨è®ºï¼Œå·ç§°æ™ºé©¾çš„è½¦ï¼Œè¿ä¸ªå±é™©åˆ¹è½¦éƒ½ä¸åšï¼ŸçœŸçš„åšä¸ åˆ°ï¼Ÿ[è—ç‹]",
        "é›·åœ£çš„æ©æƒ…è¿˜ä¸å®Œ\nğŸ–ï¸   ğŸ–ï¸       ğŸ–ï¸   ğŸ–ï¸      ğŸ–ï¸   ğŸ–ï¸\n  \\ğŸ˜­/            \\ğŸ˜­/           \\ğŸ˜­/\n    ğŸ‘•               ğŸ‘•...",
        # æ›´éšæ™¦çš„ä¾‹å­
        "ğŸ˜…ğŸ˜…è¿™å…¬å…³æ–‡å†™å¾—çœŸå¥½ï¼Œä¸‹æ¬¡åˆ«å†™äº†ã€‚",
        "åªèƒ½è¯´æ‡‚å¾—éƒ½æ‡‚ï¼Œä¸æ‡‚çš„è¯´äº†ä¹Ÿä¸æ‡‚ã€‚",
        "åˆæ˜¯ç†Ÿæ‚‰çš„é…æ–¹ï¼Œç†Ÿæ‚‰çš„å‘³é“ã€‚",
        "è¿™è¯„è®ºåŒºç”»é£æœç„¶ä¸ä¸€æ ·ã€‚[doge]",
        "é¥é¥é¢†å…ˆï¼(ä¸æ˜¯)", # åè®½
        "æˆ‘ä»€ä¹ˆéƒ½æ²¡è¯´ï¼Œåªæ˜¯å‘ä¸ªè¡¨æƒ…[åƒç“œ]",
        "ç­‰ä¸€ä¸ªåè½¬ï¼Œæ€»æ„Ÿè§‰æ²¡é‚£ä¹ˆç®€å•ã€‚",
        "ä¸æ˜¯å§é˜¿sirï¼Œè¿™ä¹Ÿèƒ½æ´—ï¼Ÿ"
    ]

    print("\\n======= å°ç±³è½¦ç¥¸è¯„è®ºåŠéšæ™¦è¨€è®ºè¯†åˆ«æµ‹è¯• (ä½¿ç”¨ detect_huawei_fanatic) =======")
    detected_count = 0
    for i, comment in enumerate(test_comments):
        # ç°åœ¨ç›´æ¥è°ƒç”¨ä¸»æ£€æµ‹æ¥å£
        is_extreme, result = detector.detect_huawei_fanatic(comment, comment_id=f"test_{i+1}")
        print(f"\\n{i+1}. è¯„è®º: {comment[:80]}..." if len(comment) > 80 else f"\\n{i+1}. è¯„è®º: {comment}")
        print(f"   è¯†åˆ«ç»“æœ: {'âœ“ æç«¯è¨€è®º' if is_extreme else 'âœ— æ­£å¸¸è¨€è®º'}")
        print(f"   ç½®ä¿¡åº¦: {result.get('confidence', 0):.2f}")
        if is_extreme:
             print(f"   åˆ¤å®šç†ç”±: {result.get('detection_summary', {}).get('reasoning', 'N/A')}")
             print(f"   æç«¯ç±»å‹: {', '.join(result.get('detection_summary', {}).get('extreme_types', []))}")
        else:
             # å¯¹äºæœªè¯†åˆ«çš„ï¼Œä¹Ÿæ‰“å°æ¨ç†è¿‡ç¨‹å¸®åŠ©åˆ†æ
             print(f"   (æœªè¾¾æ ‡)æ¨ç†: {result.get('detection_summary', {}).get('reasoning', 'N/A')}")

        if is_extreme:
            detected_count += 1

    print(f"\\næ€»ç»“: å…±æµ‹è¯• {len(test_comments)} æ¡è¯„è®ºï¼Œè¯†åˆ«ä¸ºæç«¯è¨€è®º {detected_count} æ¡ï¼Œæ£€å‡ºç‡: {detected_count/len(test_comments)*100:.1f}%")
    print("\\n=======================================================================")

if __name__ == "__main__":
    # åˆå§‹åŒ–æ—¥å¿— (ç¡®ä¿å³ä½¿ä¸é€šè¿‡ BilibiliCommentDetector ç±»è°ƒç”¨ä¹Ÿèƒ½è®°å½•)
    if not logging.getLogger("HuaweiFanaticDetector").handlers:
         log_dir = "logs"
         if not os.path.exists(log_dir): os.makedirs(log_dir)
         current_time = datetime.now().strftime("%Y%m%d_%H%M%S")
         log_file = os.path.join(log_dir, f"fanatic_detector_test_{current_time}.log")
         logging.basicConfig(level=logging.INFO,
                             format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
                             handlers=[logging.FileHandler(log_file, encoding='utf-8'), logging.StreamHandler()])
         logging.info("ç‹¬ç«‹è¿è¡Œæµ‹è¯•ï¼Œåˆå§‹åŒ–æ—¥å¿—ã€‚")

    test_xiaomi_car_comments()
